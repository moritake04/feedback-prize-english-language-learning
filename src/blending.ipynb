{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:13.310739Z",
     "iopub.status.busy": "2022-11-29T04:28:13.309852Z",
     "iopub.status.idle": "2022-11-29T04:28:13.317104Z",
     "shell.execute_reply": "2022-11-29T04:28:13.316497Z",
     "shell.execute_reply.started": "2022-11-29T04:28:13.310668Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(\"../../weights\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYtAu4VWDoao"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:15.326999Z",
     "iopub.status.busy": "2022-11-29T04:28:15.326706Z",
     "iopub.status.idle": "2022-11-29T04:28:19.354113Z",
     "shell.execute_reply": "2022-11-29T04:28:19.353383Z",
     "shell.execute_reply.started": "2022-11-29T04:28:15.326976Z"
    },
    "executionInfo": {
     "elapsed": 3718,
     "status": "ok",
     "timestamp": 1662355265196,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "Wy2A_ZTLDoaq"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import sklearn.metrics as metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml \n",
    "import joblib\n",
    "from sklearn import linear_model\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WMRIZRfDoZ3"
   },
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:19.356391Z",
     "iopub.status.busy": "2022-11-29T04:28:19.355461Z",
     "iopub.status.idle": "2022-11-29T04:28:19.432685Z",
     "shell.execute_reply": "2022-11-29T04:28:19.432077Z",
     "shell.execute_reply.started": "2022-11-29T04:28:19.356366Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./configs/deberta_v3_base_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg1 = yaml.safe_load(f)\n",
    "cfg1[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg1[\"model_save\"] = False\n",
    "cfg1[\"enable_checkpointing\"] = False\n",
    "cfg1[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg1[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg1['save_weight_folder'] = \"../../weights/deberta_v3_base_512_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_base_4096_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg2 = yaml.safe_load(f)\n",
    "cfg2[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg2[\"model_save\"] = False\n",
    "cfg2[\"enable_checkpointing\"] = False\n",
    "cfg2[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg2[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg2['save_weight_folder'] = \"../../weights/deberta_v3_base_4096_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_large_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg3 = yaml.safe_load(f)\n",
    "cfg3[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg3[\"model_save\"] = False\n",
    "cfg3[\"enable_checkpointing\"] = False\n",
    "cfg3[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg3[\"model_name\"] = \"../input/deberta-v3-large\"\n",
    "cfg3['save_weight_folder'] = \"../../weights/deberta_v3_large_512_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_large_4096_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg4 = yaml.safe_load(f)\n",
    "cfg4[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg4[\"model_save\"] = False\n",
    "cfg4[\"enable_checkpointing\"] = False\n",
    "cfg4[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg4[\"model_name\"] = \"../input/deberta-v3-large\"\n",
    "cfg4['save_weight_folder'] = \"../../weights/deberta_v3_large_4096_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_large_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg5 = yaml.safe_load(f)\n",
    "cfg5[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg5[\"model_save\"] = False\n",
    "cfg5[\"enable_checkpointing\"] = False\n",
    "cfg5[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg5[\"model_name\"] = \"../input/deberta-large\"\n",
    "cfg5['save_weight_folder'] = \"../../weights/deberta_large_512_reinit\"\n",
    "\n",
    "with open(\"./configs/muppet_large_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg6 = yaml.safe_load(f)\n",
    "cfg6[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg6[\"model_save\"] = False\n",
    "cfg6[\"enable_checkpointing\"] = False\n",
    "cfg6[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg6[\"model_name\"] = \"../input/muppet-roberta-large\"\n",
    "cfg6['save_weight_folder'] = \"../../weights/muppet_large_512_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_xlarge_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg7 = yaml.safe_load(f)\n",
    "cfg7[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg7[\"model_save\"] = False\n",
    "cfg7[\"enable_checkpointing\"] = False\n",
    "cfg7[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg7[\"model_name\"] = \"../input/debertaxlarge\"\n",
    "cfg7['save_weight_folder'] = \"../../weights/deberta_xlarge_512_reinit\"\n",
    "\n",
    "with open(\"./configs/mpnet_base_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg8 = yaml.safe_load(f)\n",
    "cfg8[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg8[\"model_save\"] = False\n",
    "cfg8[\"enable_checkpointing\"] = False\n",
    "cfg8[\"pl_params\"][\"precision\"] = 32\n",
    "cfg8['save_weight_folder'] = \"../../weights/mpnet_base_512_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_small_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg9 = yaml.safe_load(f)\n",
    "cfg9[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg9[\"model_save\"] = False\n",
    "cfg9[\"enable_checkpointing\"] = False\n",
    "cfg9[\"pl_params\"][\"precision\"] = 32\n",
    "cfg9['save_weight_folder'] = \"../../weights/deberta_v3_small_512_reinit\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_xsmall_512_reinit.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg10 = yaml.safe_load(f)\n",
    "cfg10[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg10[\"model_save\"] = False\n",
    "cfg10[\"enable_checkpointing\"] = False\n",
    "cfg10[\"pl_params\"][\"precision\"] = 32\n",
    "cfg10['save_weight_folder'] = \"../../weights/deberta_v3_xsmall_512_reinit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:19.433640Z",
     "iopub.status.busy": "2022-11-29T04:28:19.433444Z",
     "iopub.status.idle": "2022-11-29T04:28:19.507834Z",
     "shell.execute_reply": "2022-11-29T04:28:19.507237Z",
     "shell.execute_reply.started": "2022-11-29T04:28:19.433621Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./configs/deberta_v3_base_512_reinit_pseudo3.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg1p = yaml.safe_load(f)\n",
    "cfg1p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg1p[\"model_save\"] = False\n",
    "cfg1p[\"enable_checkpointing\"] = False\n",
    "cfg1p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg1p[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg1p['save_weight_folder'] = \"../../weights/deberta_v3_base_512_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_base_4096_reinit_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg2p = yaml.safe_load(f)\n",
    "cfg2p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg2p[\"model_save\"] = False\n",
    "cfg2p[\"enable_checkpointing\"] = False\n",
    "cfg2p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg2p[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg2p['save_weight_folder'] = \"../../weights/deberta_v3_base_4096_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_large_512_reinit_pseudo3.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg3p = yaml.safe_load(f)\n",
    "cfg3p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg3p[\"model_save\"] = False\n",
    "cfg3p[\"enable_checkpointing\"] = False\n",
    "cfg3p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg3p[\"model_name\"] = \"../input/deberta-v3-large\"\n",
    "cfg3p['save_weight_folder'] = \"../../weights/deberta_v3_large_512_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_large_4096_reinit_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg4p = yaml.safe_load(f)\n",
    "cfg4p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg4p[\"model_save\"] = False\n",
    "cfg4p[\"enable_checkpointing\"] = False\n",
    "cfg4p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg4p[\"model_name\"] = \"../input/deberta-v3-large\"\n",
    "cfg4p['save_weight_folder'] = \"../../weights/deberta_v3_large_4096_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/deberta_large_512_reinit_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg5p = yaml.safe_load(f)\n",
    "cfg5p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg5p[\"model_save\"] = False\n",
    "cfg5p[\"enable_checkpointing\"] = False\n",
    "cfg5p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg5p[\"model_name\"] = \"../input/deberta-large\"\n",
    "cfg5p['save_weight_folder'] = \"../../weights/deberta_large_512_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/muppet_large_512_reinit_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg6p = yaml.safe_load(f)\n",
    "cfg6p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg6p[\"model_save\"] = False\n",
    "cfg6p[\"enable_checkpointing\"] = False\n",
    "cfg6p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg6p[\"model_name\"] = \"../input/muppet-roberta-large\"\n",
    "cfg6p['save_weight_folder'] = \"../../weights/muppet_large_512_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/deberta_xlarge_512_reinit_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg7p = yaml.safe_load(f)\n",
    "cfg7p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg7p[\"model_save\"] = False\n",
    "cfg7p[\"enable_checkpointing\"] = False\n",
    "cfg7p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg7p[\"model_name\"] = \"../input/debertaxlarge\"\n",
    "cfg7p['save_weight_folder'] = \"../../weights/deberta_xlarge_512_reinit_pseudo\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_base_512_reinit_pseudo3_cls.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg8p = yaml.safe_load(f)\n",
    "cfg8p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg8p[\"model_save\"] = False\n",
    "cfg8p[\"enable_checkpointing\"] = False\n",
    "cfg8p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg8p[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg8p['save_weight_folder'] = \"../../weights/deberta_v3_base_512_reinit_pseudo3_cls\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_base_512_reinit_pseudo3_wap_attention.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg9p = yaml.safe_load(f)\n",
    "cfg9p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg9p[\"model_save\"] = False\n",
    "cfg9p[\"enable_checkpointing\"] = False\n",
    "cfg9p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg9p[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg9p['save_weight_folder'] = \"../weights/deberta_v3_base_512_reinit_pseudo3_wap_attention\"\n",
    "\n",
    "with open(\"./configs/deberta_v3_base_512_reinit_pseudo3_wap_attention_3epoch.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg10p = yaml.safe_load(f)\n",
    "cfg10p[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg10p[\"model_save\"] = False\n",
    "cfg10p[\"enable_checkpointing\"] = False\n",
    "cfg10p[\"pl_params\"][\"precision\"] = 32\n",
    "#cfg10p[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg10p['save_weight_folder'] = \"../weights/deberta_v3_base_512_reinit_pseudo3_wap_attention_3epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:19.509718Z",
     "iopub.status.busy": "2022-11-29T04:28:19.509186Z",
     "iopub.status.idle": "2022-11-29T04:28:19.786170Z",
     "shell.execute_reply": "2022-11-29T04:28:19.785559Z",
     "shell.execute_reply.started": "2022-11-29T04:28:19.509696Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./configs/svr/albert_xxlarge_v2_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg1s = yaml.safe_load(f)\n",
    "cfg1s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg1s[\"model_save\"] = False\n",
    "cfg1s[\"enable_checkpointing\"] = False\n",
    "cfg1s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg1s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg1s['save_weight_folder'] = \"../../weights/albert_xxlarge_v2_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/bigbird_roberta_large_4096_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg2s = yaml.safe_load(f)\n",
    "cfg2s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg2s[\"model_save\"] = False\n",
    "cfg2s[\"enable_checkpointing\"] = False\n",
    "cfg2s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg2s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg2s['save_weight_folder'] = \"../../weights/bigbird_roberta_large_4096_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_large_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg3s = yaml.safe_load(f)\n",
    "cfg3s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg3s[\"model_save\"] = False\n",
    "cfg3s[\"enable_checkpointing\"] = False\n",
    "cfg3s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg3s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg3s['save_weight_folder'] = \"../../weights/deberta_large_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v2_xlarge_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg4s = yaml.safe_load(f)\n",
    "cfg4s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg4s[\"model_save\"] = False\n",
    "cfg4s[\"enable_checkpointing\"] = False\n",
    "cfg4s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg4s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg4s['save_weight_folder'] = \"../../weights/deberta_v2_xlarge_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v2_xxlarge_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg5s = yaml.safe_load(f)\n",
    "cfg5s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg5s[\"model_save\"] = False\n",
    "cfg5s[\"enable_checkpointing\"] = False\n",
    "cfg5s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg5s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg5s['save_weight_folder'] = \"../../weights/deberta_v2_xxlarge_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_4096_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg6s = yaml.safe_load(f)\n",
    "cfg6s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg6s[\"model_save\"] = False\n",
    "cfg6s[\"enable_checkpointing\"] = False\n",
    "cfg6s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg6s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg6s['save_weight_folder'] = \"../../weights/deberta_v3_base_4096_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg7s = yaml.safe_load(f)\n",
    "cfg7s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg7s[\"model_save\"] = False\n",
    "cfg7s[\"enable_checkpointing\"] = False\n",
    "cfg7s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg7s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg7s['save_weight_folder'] = \"../../weights/deberta_v3_base_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_large_4096_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg8s = yaml.safe_load(f)\n",
    "cfg8s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg8s[\"model_save\"] = False\n",
    "cfg8s[\"enable_checkpointing\"] = False\n",
    "cfg8s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg8s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg8s['save_weight_folder'] = \"../../weights/deberta_v3_large_4096_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_large_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg9s = yaml.safe_load(f)\n",
    "cfg9s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg9s[\"model_save\"] = False\n",
    "cfg9s[\"enable_checkpointing\"] = False\n",
    "cfg9s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg9s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg9s['save_weight_folder'] = \"../../weights/deberta_v3_large_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_xlarge_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg10s = yaml.safe_load(f)\n",
    "cfg10s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg10s[\"model_save\"] = False\n",
    "cfg10s[\"enable_checkpointing\"] = False\n",
    "cfg10s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg10s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg10s['save_weight_folder'] = \"../../weights/deberta_xlarge_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/electra_large_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg11s = yaml.safe_load(f)\n",
    "cfg11s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg11s[\"model_save\"] = False\n",
    "cfg11s[\"enable_checkpointing\"] = False\n",
    "cfg11s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg11s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg11s['save_weight_folder'] = \"../../weights/electra_large_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/funnel_xlarge_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg12s = yaml.safe_load(f)\n",
    "cfg12s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg12s[\"model_save\"] = False\n",
    "cfg12s[\"enable_checkpointing\"] = False\n",
    "cfg12s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg12s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg12s['save_weight_folder'] = \"../../weights/funnel_xlarge_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/longformer_large_4096.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg13s = yaml.safe_load(f)\n",
    "cfg13s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg13s[\"model_save\"] = False\n",
    "cfg13s[\"enable_checkpointing\"] = False\n",
    "cfg13s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg13s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg13s['save_weight_folder'] = \"../../weights/longformer_large_4096\"\n",
    "\n",
    "with open(\"./configs/svr/muppet_large_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg14s = yaml.safe_load(f)\n",
    "cfg14s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg14s[\"model_save\"] = False\n",
    "cfg14s[\"enable_checkpointing\"] = False\n",
    "cfg14s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg14s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg14s['save_weight_folder'] = \"../../weights/muppet_large_512_svr\"\n",
    "\n",
    "with open(\"./configs/svr/roberta_large_512_svr.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg15s = yaml.safe_load(f)\n",
    "cfg15s[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg15s[\"model_save\"] = False\n",
    "cfg15s[\"enable_checkpointing\"] = False\n",
    "cfg15s[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg15s[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg15s['save_weight_folder'] = \"../../weights/roberta_large_512_svr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:19.787348Z",
     "iopub.status.busy": "2022-11-29T04:28:19.787149Z",
     "iopub.status.idle": "2022-11-29T04:28:19.955585Z",
     "shell.execute_reply": "2022-11-29T04:28:19.954904Z",
     "shell.execute_reply.started": "2022-11-29T04:28:19.787328Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./configs/svr/deberta_v3_base_4096_reinit_svr_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg1sp = yaml.safe_load(f)\n",
    "cfg1sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg1sp[\"model_save\"] = False\n",
    "cfg1sp[\"enable_checkpointing\"] = False\n",
    "cfg1sp[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg1sp[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg1sp['save_weight_folder'] = \"../../weights/deberta_v3_base_4096_reinit_svr_pseudo\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_512_reinit_svr_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg2sp = yaml.safe_load(f)\n",
    "cfg2sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg2sp[\"model_save\"] = False\n",
    "cfg2sp[\"enable_checkpointing\"] = False\n",
    "cfg2sp[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg2sp[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg2sp['save_weight_folder'] = \"../../weights/deberta_v3_base_512_reinit_svr_pseudo\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_large_4096_reinit_svr_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg3sp = yaml.safe_load(f)\n",
    "cfg3sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg3sp[\"model_save\"] = False\n",
    "cfg3sp[\"enable_checkpointing\"] = False\n",
    "cfg3sp[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg3sp[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg3sp['save_weight_folder'] = \"../../weights/deberta_v3_large_4096_reinit_svr_pseudo\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_large_512_reinit_svr_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg4sp = yaml.safe_load(f)\n",
    "cfg4sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg4sp[\"model_save\"] = False\n",
    "cfg4sp[\"enable_checkpointing\"] = False\n",
    "cfg4sp[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg4sp[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg4sp['save_weight_folder'] = \"../../weights/deberta_v3_large_512_reinit_svr_pseudo\"\n",
    "\n",
    "with open(\"./configs/svr/deberta_xlarge_512_reinit_svr_pseudo.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg5sp = yaml.safe_load(f)\n",
    "cfg5sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg5sp[\"model_save\"] = False\n",
    "cfg5sp[\"enable_checkpointing\"] = False\n",
    "cfg5sp[\"pl_params\"][\"precision\"] = 16\n",
    "#cfg5sp[\"model_name\"] = \"../input/deberta-v3-base\"\n",
    "cfg5sp['save_weight_folder'] = \"../../weights/deberta_xlarge_512_reinit_svr_pseudo\"\n",
    "\n",
    "# 1128追加\n",
    "with open(\"./configs/svr/deberta_v3_base_512_reinit_svr_pseudo_wap.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg6sp = yaml.safe_load(f)\n",
    "cfg6sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg6sp[\"model_save\"] = False\n",
    "cfg6sp[\"enable_checkpointing\"] = False\n",
    "cfg6sp[\"pl_params\"][\"precision\"] = 16\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_512_reinit_svr_pseudo_wap_all.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg7sp = yaml.safe_load(f)\n",
    "cfg7sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg7sp[\"model_save\"] = False\n",
    "cfg7sp[\"enable_checkpointing\"] = False\n",
    "cfg7sp[\"pl_params\"][\"precision\"] = 16\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_512_reinit_svr_pseudo_mean_pooling_concatenate.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg8sp = yaml.safe_load(f)\n",
    "cfg8sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg8sp[\"model_save\"] = False\n",
    "cfg8sp[\"enable_checkpointing\"] = False\n",
    "cfg8sp[\"pl_params\"][\"precision\"] = 16\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_4096_reinit_svr_pseudo_wap.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg9sp = yaml.safe_load(f)\n",
    "cfg9sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg9sp[\"model_save\"] = False\n",
    "cfg9sp[\"enable_checkpointing\"] = False\n",
    "cfg9sp[\"pl_params\"][\"precision\"] = 16\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_4096_reinit_svr_pseudo_wap_all.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg10sp = yaml.safe_load(f)\n",
    "cfg10sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg10sp[\"model_save\"] = False\n",
    "cfg10sp[\"enable_checkpointing\"] = False\n",
    "cfg10sp[\"pl_params\"][\"precision\"] = 16\n",
    "\n",
    "with open(\"./configs/svr/deberta_v3_base_4096_reinit_svr_pseudo_mean_pooling_concatenate.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg11sp = yaml.safe_load(f)\n",
    "cfg11sp[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg11sp[\"model_save\"] = False\n",
    "cfg11sp[\"enable_checkpointing\"] = False\n",
    "cfg11sp[\"pl_params\"][\"precision\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:33.852139Z",
     "iopub.status.busy": "2022-11-29T04:28:33.851838Z",
     "iopub.status.idle": "2022-11-29T04:28:33.862265Z",
     "shell.execute_reply": "2022-11-29T04:28:33.861130Z",
     "shell.execute_reply.started": "2022-11-29T04:28:33.852110Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./configs/deberta_v3_base_512_reinit_mse.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg1mse = yaml.safe_load(f)\n",
    "cfg1mse[\"general\"][\"wandb_desabled\"] = True\n",
    "cfg1mse[\"model_save\"] = False\n",
    "cfg1mse[\"enable_checkpointing\"] = False\n",
    "cfg1mse[\"pl_params\"][\"precision\"] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T10:50:30.777255Z",
     "iopub.status.busy": "2022-11-28T10:50:30.776838Z",
     "iopub.status.idle": "2022-11-28T10:50:30.780627Z",
     "shell.execute_reply": "2022-11-28T10:50:30.779898Z",
     "shell.execute_reply.started": "2022-11-28T10:50:30.777232Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1, cfg2, cfg3, cfg4, cfg5, cfg6, cfg7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T10:50:31.600545Z",
     "iopub.status.busy": "2022-11-28T10:50:31.599974Z",
     "iopub.status.idle": "2022-11-28T10:50:31.603715Z",
     "shell.execute_reply": "2022-11-28T10:50:31.603005Z",
     "shell.execute_reply.started": "2022-11-28T10:50:31.600523Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1p, cfg2p, cfg3p, cfg4p, cfg5p, cfg6p, cfg7p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T10:50:32.693327Z",
     "iopub.status.busy": "2022-11-28T10:50:32.692714Z",
     "iopub.status.idle": "2022-11-28T10:50:32.697324Z",
     "shell.execute_reply": "2022-11-28T10:50:32.696343Z",
     "shell.execute_reply.started": "2022-11-28T10:50:32.693302Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1s, cfg2s, cfg3s, cfg4s, cfg5s, cfg6s, cfg7s, cfg8s, cfg9s, cfg10s, cfg11s, cfg12s, cfg13s, cfg14s, cfg15s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T10:50:33.787827Z",
     "iopub.status.busy": "2022-11-28T10:50:33.786874Z",
     "iopub.status.idle": "2022-11-28T10:50:33.791525Z",
     "shell.execute_reply": "2022-11-28T10:50:33.790830Z",
     "shell.execute_reply.started": "2022-11-28T10:50:33.787788Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1sp, cfg2sp, cfg3sp, cfg4sp, cfg5sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T20:23:42.274660Z",
     "iopub.status.busy": "2022-11-26T20:23:42.274367Z",
     "iopub.status.idle": "2022-11-26T20:23:42.278642Z",
     "shell.execute_reply": "2022-11-26T20:23:42.277998Z",
     "shell.execute_reply.started": "2022-11-26T20:23:42.274637Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1, cfg2, cfg3, cfg4, cfg5, cfg6, cfg7, cfg1p, cfg2p, cfg3p, cfg4p, cfg5p, cfg6p, cfg7p, cfg1s, cfg2s, cfg3s, cfg4s, cfg5s, cfg6s, cfg7s, cfg8s, cfg9s, cfg10s, cfg11s, cfg12s, cfg13s, cfg14s, cfg15s, cfg1sp, cfg2sp, cfg3sp, cfg4sp, cfg5sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T07:34:08.886784Z",
     "iopub.status.busy": "2022-11-27T07:34:08.886492Z",
     "iopub.status.idle": "2022-11-27T07:34:08.890398Z",
     "shell.execute_reply": "2022-11-27T07:34:08.889544Z",
     "shell.execute_reply.started": "2022-11-27T07:34:08.886762Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1126 sub\n",
    "cfg_list = [cfg1, cfg2, cfg5, cfg6, cfg7, cfg1p, cfg3p, cfg4p, cfg7p, cfg2sp, cfg3sp, cfg4sp, cfg5sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T10:52:43.558358Z",
     "iopub.status.busy": "2022-11-28T10:52:43.557623Z",
     "iopub.status.idle": "2022-11-28T10:52:43.561287Z",
     "shell.execute_reply": "2022-11-28T10:52:43.560782Z",
     "shell.execute_reply.started": "2022-11-28T10:52:43.558333Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1128 深夜\n",
    "cfg_list = [cfg1, cfg2, cfg5, cfg6, cfg7, cfg1p, cfg3p, cfg4p, cfg7p, cfg2sp, cfg3sp, cfg4sp, cfg5sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T07:31:47.029260Z",
     "iopub.status.busy": "2022-11-26T07:31:47.028737Z",
     "iopub.status.idle": "2022-11-26T07:31:47.032684Z",
     "shell.execute_reply": "2022-11-26T07:31:47.032006Z",
     "shell.execute_reply.started": "2022-11-26T07:31:47.029236Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1, cfg2, cfg3, cfg4, cfg5, cfg6, cfg7, cfg1p, cfg2p, cfg3p, cfg4p, cfg5p, cfg6p, cfg7p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T07:36:08.695711Z",
     "iopub.status.busy": "2022-11-27T07:36:08.695079Z",
     "iopub.status.idle": "2022-11-27T07:36:08.700400Z",
     "shell.execute_reply": "2022-11-27T07:36:08.699132Z",
     "shell.execute_reply.started": "2022-11-27T07:36:08.695687Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1, cfg2, cfg5, cfg6, cfg7, cfg1p, cfg3p, cfg4p, cfg7p] # best subしたやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T10:54:59.380332Z",
     "iopub.status.busy": "2022-11-28T10:54:59.379409Z",
     "iopub.status.idle": "2022-11-28T10:54:59.383478Z",
     "shell.execute_reply": "2022-11-28T10:54:59.382778Z",
     "shell.execute_reply.started": "2022-11-28T10:54:59.380305Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg1, cfg2, cfg5, cfg6, cfg7, cfg1p, cfg3p, cfg4p, cfg7p, cfg1s, cfg2s, cfg3s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:42.734640Z",
     "iopub.status.busy": "2022-11-29T04:28:42.734066Z",
     "iopub.status.idle": "2022-11-29T04:28:42.738524Z",
     "shell.execute_reply": "2022-11-29T04:28:42.737772Z",
     "shell.execute_reply.started": "2022-11-29T04:28:42.734613Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list = [cfg2, cfg5, cfg6, cfg7, cfg1p, cfg4p, cfg7p, cfg2sp, cfg3sp, cfg5sp, cfg8s, cfg3s, cfg6s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:42.992019Z",
     "iopub.status.busy": "2022-11-29T04:28:42.991610Z",
     "iopub.status.idle": "2022-11-29T04:28:42.995851Z",
     "shell.execute_reply": "2022-11-29T04:28:42.995052Z",
     "shell.execute_reply.started": "2022-11-29T04:28:42.991991Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_list += [cfg1mse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmES5GjMDoa6"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:44.778947Z",
     "iopub.status.busy": "2022-11-29T04:28:44.778665Z",
     "iopub.status.idle": "2022-11-29T04:28:44.829791Z",
     "shell.execute_reply": "2022-11-29T04:28:44.829100Z",
     "shell.execute_reply.started": "2022-11-29T04:28:44.778923Z"
    }
   },
   "outputs": [],
   "source": [
    "def mcrmse(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:, i]\n",
    "        y_pred = y_preds[:, i]\n",
    "        score = metrics.mean_squared_error(y_true, y_pred, squared=False)  # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        )\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = (\n",
    "            layer_weights\n",
    "            if layer_weights is not None\n",
    "            else nn.Parameter(\n",
    "                torch.tensor(\n",
    "                    [1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start :, :, :, :]\n",
    "        weight_factor = (\n",
    "            self.layer_weights.unsqueeze(-1)\n",
    "            .unsqueeze(-1)\n",
    "            .unsqueeze(-1)\n",
    "            .expand(all_layer_embedding.size())\n",
    "        )\n",
    "        weighted_average = (weight_factor * all_layer_embedding).sum(\n",
    "            dim=0\n",
    "        ) / self.layer_weights.sum()\n",
    "        return weighted_average\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.att = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, last_hidden_state):\n",
    "        att_weights = self.att(last_hidden_state)\n",
    "        feature = torch.sum(att_weights * last_hidden_state, dim=1)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class TransformersModel(pl.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.criterion = nn.__dict__[cfg[\"criterion\"]]()\n",
    "\n",
    "        # awp\n",
    "        if cfg[\"awp\"] is not None:\n",
    "            self.automatic_optimization = False\n",
    "            self.adv_param = cfg[\"awp\"][\"adv_param\"]\n",
    "            self.adv_lr = cfg[\"awp\"][\"adv_lr\"]\n",
    "            self.adv_eps = cfg[\"awp\"][\"adv_eps\"]\n",
    "            self.adv_step = cfg[\"awp\"][\"adv_step\"]\n",
    "            self.backup = {}\n",
    "            self.backup_eps = {}\n",
    "            self.awp_accumulate_grad_batches = cfg[\"awp\"][\"accumulate_grad_batches\"]\n",
    "            # self.awp_scaler = torch.cuda.amp.GradScaler(enabled=cfg[\"awp\"][\"amp\"])\n",
    "            if cfg[\"awp\"][\"gradient_clip_val\"] is not None:\n",
    "                self.awp_max_grad_norm = cfg[\"awp\"][\"gradient_clip_val\"]\n",
    "            else:\n",
    "                self.awp_max_grad_norm = None\n",
    "            self.awp_start_epoch = cfg[\"awp\"][\"start_epoch\"]\n",
    "\n",
    "        # model\n",
    "        if cfg[\"mlm\"]:\n",
    "            print(f\"../weights/mlm_model/{cfg['model_name']}\")\n",
    "            self.tr_config = AutoConfig.from_pretrained(\n",
    "                f\"../weights/mlm_model/{cfg['model_name']}\", output_hidden_states=True\n",
    "            )\n",
    "        else:\n",
    "            self.tr_config = AutoConfig.from_pretrained(\n",
    "                cfg[\"model_name\"], output_hidden_states=True\n",
    "            )\n",
    "\n",
    "        self.tr_config.hidden_dropout = 0.0\n",
    "        self.tr_config.hidden_dropout_prob = 0.0\n",
    "        self.tr_config.attention_dropout = 0.0\n",
    "        self.tr_config.attention_probs_dropout_prob = 0.0\n",
    "\n",
    "        if cfg[\"mlm\"]:\n",
    "            self.model = AutoModel.from_pretrained(\n",
    "                f\"../weights/mlm_model/{cfg['model_name']}\", config=self.tr_config\n",
    "            )\n",
    "        elif cfg[\"pretrained\"]:\n",
    "            self.model = AutoModel.from_pretrained(\n",
    "                cfg[\"model_name\"], config=self.tr_config\n",
    "            )\n",
    "        else:\n",
    "            self.model = AutoModel(self.tr_config)\n",
    "        if self.cfg[\"transformers_params\"][\"gradient_checkpointing\"]:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        if cfg[\"preprocess\"]:\n",
    "            self.model.resize_token_embeddings(len(cfg[\"tokenizer\"]))\n",
    "\n",
    "        # header\n",
    "        if cfg[\"header\"] == \"cls\":\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"mean_pooling\":\n",
    "            self.pool = MeanPooling()\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"attention\":\n",
    "            self.attention = AttentionHead(self.tr_config.hidden_size)\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"weighted_average_pooling\":\n",
    "            layer_start = (\n",
    "                self.tr_config.num_hidden_layers + 1\n",
    "            ) - 4  # use last 4-layers\n",
    "            self.wl_pool = WeightedLayerPooling(\n",
    "                self.tr_config.num_hidden_layers,\n",
    "                layer_start=layer_start,\n",
    "                layer_weights=None,\n",
    "            )\n",
    "            self.m_pool = MeanPooling()\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"cls_concatenate\":\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size * 4, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"mean_pooling_concatenate\":\n",
    "            self.pool = MeanPooling()\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size * 4, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"1dcnn\":\n",
    "            self.cnn1 = nn.Conv1d(\n",
    "                self.tr_config.hidden_size, 256, kernel_size=2, padding=1\n",
    "            )\n",
    "            self.cnn2 = nn.Conv1d(256, 6, kernel_size=2, padding=1)\n",
    "        elif cfg[\"header\"] == \"lstm\":\n",
    "            self.lstm = nn.LSTM(\n",
    "                self.tr_config.hidden_size,\n",
    "                self.tr_config.hidden_size,\n",
    "                batch_first=True,\n",
    "            )\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size, 6)\n",
    "            self._init_weights(self.fc)\n",
    "        elif cfg[\"header\"] == \"gru\":\n",
    "            self.gru = nn.GRU(\n",
    "                self.tr_config.hidden_size,\n",
    "                self.tr_config.hidden_size,\n",
    "                batch_first=True,\n",
    "            )\n",
    "            self.fc = nn.Linear(self.tr_config.hidden_size, 6)\n",
    "            self._init_weights(self.fc)\n",
    "\n",
    "        # reinit same layers\n",
    "        if cfg[\"transformers_params\"][\"reinit_layers\"] is not None:\n",
    "            print(f\"reinit {cfg['transformers_params']['reinit_layers']} layers\")\n",
    "            self._reinit_layer(self.model)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.tr_config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.tr_config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def _reinit_layer(self, model):\n",
    "        if \"funnel\" in self.cfg[\"model_name\"]:\n",
    "            for layer in model.decoder.layers[\n",
    "                -self.cfg[\"transformers_params\"][\"reinit_layers\"] :\n",
    "            ]:\n",
    "                for module in layer.modules():\n",
    "                    if isinstance(module, nn.Linear):\n",
    "                        module.weight.data.normal_(\n",
    "                            mean=0.0, std=model.config.initializer_range\n",
    "                        )\n",
    "                        if module.bias is not None:\n",
    "                            module.bias.data.zero_()\n",
    "                    elif isinstance(module, nn.Embedding):\n",
    "                        module.weight.data.normal_(\n",
    "                            mean=0.0, std=model.config.initializer_range\n",
    "                        )\n",
    "                        if module.padding_idx is not None:\n",
    "                            module.weight.data[module.padding_idx].zero_()\n",
    "                    elif isinstance(module, nn.LayerNorm):\n",
    "                        module.bias.data.zero_()\n",
    "                        module.weight.data.fill_(1.0)\n",
    "        else:\n",
    "            for layer in model.encoder.layer[\n",
    "                -self.cfg[\"transformers_params\"][\"reinit_layers\"] :\n",
    "            ]:\n",
    "                for module in layer.modules():\n",
    "                    if isinstance(module, nn.Linear):\n",
    "                        module.weight.data.normal_(\n",
    "                            mean=0.0, std=model.config.initializer_range\n",
    "                        )\n",
    "                        if module.bias is not None:\n",
    "                            module.bias.data.zero_()\n",
    "                    elif isinstance(module, nn.Embedding):\n",
    "                        module.weight.data.normal_(\n",
    "                            mean=0.0, std=model.config.initializer_range\n",
    "                        )\n",
    "                        if module.padding_idx is not None:\n",
    "                            module.weight.data[module.padding_idx].zero_()\n",
    "                    elif isinstance(module, nn.LayerNorm):\n",
    "                        module.bias.data.zero_()\n",
    "                        module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        if self.cfg[\"header\"] == \"cls\":\n",
    "            last_hidden_states = outputs[0][:, 0]\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(outputs, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(last_hidden_states)\n",
    "        elif self.cfg[\"header\"] == \"mean_pooling\":\n",
    "            last_hidden_states = outputs[0]\n",
    "            feature = self.pool(last_hidden_states, inputs[\"attention_mask\"])\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        elif self.cfg[\"header\"] == \"attention\":\n",
    "            last_hidden_states = outputs[0]\n",
    "            feature = self.attention(last_hidden_states)\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        elif self.cfg[\"header\"] == \"weighted_average_pooling\":\n",
    "            all_hidden_states = torch.stack(outputs[\"hidden_states\"])\n",
    "            weighted_pooling_embeddings = self.wl_pool(all_hidden_states)\n",
    "            feature = self.m_pool(weighted_pooling_embeddings, inputs[\"attention_mask\"])\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        elif self.cfg[\"header\"] == \"cls_concatenate\":\n",
    "            feature = torch.cat(\n",
    "                [outputs[\"hidden_states\"][-1 * i][:, 0] for i in range(1, 4 + 1)], dim=1\n",
    "            )\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        if self.cfg[\"header\"] == \"mean_pooling_concatenate\":\n",
    "            features = []\n",
    "            for i in range(1, 4 + 1):\n",
    "                last_hidden_states = outputs[\"hidden_states\"][-1 * i]\n",
    "                feature = self.pool(last_hidden_states, inputs[\"attention_mask\"])\n",
    "                features.append(feature)\n",
    "            feature = torch.cat(features, dim=1)\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        elif self.cfg[\"header\"] == \"1d_cnn\":\n",
    "            last_hidden_states = outputs[\"last_hidden_state\"].permute(0, 2, 1)\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(last_hidden_states, p=2, dim=1)\n",
    "            else:\n",
    "                cnn_embeddings = F.relu(self.cnn1(last_hidden_states))\n",
    "                cnn_embeddings = self.cnn2(cnn_embeddings)\n",
    "                outputs, _ = torch.max(cnn_embeddings, 2)\n",
    "        elif self.cfg[\"header\"] == \"lstm\":\n",
    "            feature, _ = self.lstm(outputs[\"last_hidden_state\"], None)\n",
    "            feature = feature[:, -1, :]\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        elif self.cfg[\"header\"] == \"gru\":\n",
    "            feature, _ = self.gru(outputs[\"last_hidden_state\"], None)\n",
    "            feature = feature[:, -1, :]\n",
    "            if self.cfg[\"retrieve_embeddings\"]:\n",
    "                outputs = F.normalize(feature, p=2, dim=1)\n",
    "            else:\n",
    "                outputs = self.fc(feature)\n",
    "        return outputs\n",
    "\n",
    "    def collate(self, inputs):\n",
    "        # 一番長いtokenへ合わせる\n",
    "        mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = inputs[k][:, :mask_len]\n",
    "        return inputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = self.collate(X)\n",
    "        if self.cfg[\"awp\"] is not None:\n",
    "            # awp step\n",
    "            opt = self.optimizers()\n",
    "            sch = self.lr_schedulers()\n",
    "\n",
    "            # with torch.cuda.amp.autocast(enabled=self.cfg[\"awp\"][\"amp\"]):\n",
    "            pred_y = self.forward(X)\n",
    "            loss = self.criterion(pred_y, y)\n",
    "\n",
    "            if self.awp_accumulate_grad_batches > 1:\n",
    "                loss = loss / self.awp_accumulate_grad_batches\n",
    "            # self.awp_scaler.scale(loss).backward()\n",
    "            self.manual_backward(loss)\n",
    "\n",
    "            if (batch_idx + 1) % self.awp_accumulate_grad_batches == 0:\n",
    "                if self.trainer.current_epoch >= self.awp_start_epoch:\n",
    "                    self._awp_save()\n",
    "                    for _ in range(self.adv_step):\n",
    "                        self._awp_attack_step()\n",
    "                        # with torch.cuda.amp.autocast(enabled=self.cfg[\"awp\"][\"amp\"]):\n",
    "                        pred_y = self.forward(X)\n",
    "                        adv_loss = self.criterion(pred_y, y)\n",
    "                        opt.zero_grad()\n",
    "                        # self.awp_scaler.scale(adv_loss).backward()\n",
    "                        self.manual_backward(adv_loss)\n",
    "                    self._awp_restore()\n",
    "\n",
    "                # self.awp_scaler.unscale_(opt)\n",
    "                # torch.nn.utils.clip_grad_norm_(\n",
    "                #    self.parameters(), self.awp_max_grad_norm\n",
    "                # )\n",
    "                # self.awp_scaler.step(opt)\n",
    "                opt.step()\n",
    "                # self.awp_scaler.update()\n",
    "                opt.zero_grad()\n",
    "                sch.step()\n",
    "        else:\n",
    "            # normal step\n",
    "            pred_y = self.forward(X)\n",
    "            loss = self.criterion(pred_y, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss_list = [x[\"loss\"] for x in outputs]\n",
    "        avg_loss = torch.stack(loss_list).mean()\n",
    "        self.log(\"train_avg_loss\", avg_loss, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = self.collate(X)\n",
    "        # if self.cfg[\"awp\"] is not None:\n",
    "        #    with torch.cuda.amp.autocast(enabled=self.cfg[\"awp\"][\"amp\"]):\n",
    "        #        pred_y = self.forward(X)\n",
    "        #        loss = self.criterion(pred_y, y)\n",
    "        # else:\n",
    "        pred_y = self.forward(X)\n",
    "        loss = self.criterion(pred_y, y)\n",
    "        return {\"valid_loss\": loss, \"preds\": pred_y, \"targets\": y}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss_list = [x[\"valid_loss\"] for x in outputs]\n",
    "        preds = torch.cat([x[\"preds\"] for x in outputs], dim=0).cpu().detach().numpy()\n",
    "        targets = (\n",
    "            torch.cat([x[\"targets\"] for x in outputs], dim=0).cpu().detach().numpy()\n",
    "        )\n",
    "        avg_loss = torch.stack(loss_list).mean()\n",
    "        score, scores = mcrmse(targets, preds)\n",
    "        self.log(\"valid_avg_loss\", avg_loss, prog_bar=True)\n",
    "        self.log(\"valid_score\", score, prog_bar=True)\n",
    "        self.log(\"valid_cohesion\", scores[0], prog_bar=True)\n",
    "        self.log(\"valid_syntax\", scores[1], prog_bar=True)\n",
    "        self.log(\"valid_vocabulary\", scores[2], prog_bar=True)\n",
    "        self.log(\"valid_phraseology\t\", scores[3], prog_bar=True)\n",
    "        self.log(\"valid_grammar\", scores[4], prog_bar=True)\n",
    "        self.log(\"valid_conventions\", scores[5], prog_bar=True)\n",
    "        return avg_loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        X, _ = batch\n",
    "        X = self.collate(X)\n",
    "        pred_y = self.forward(X)\n",
    "        return pred_y\n",
    "\n",
    "    def get_scheduler(self, optimizer, num_train_steps):\n",
    "        if self.cfg[\"transformers_params\"][\"scheduler\"] == \"linear\":\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=self.cfg[\"transformers_params\"][\"warmup_ratio\"]\n",
    "                * num_train_steps,\n",
    "                num_training_steps=num_train_steps,\n",
    "            )\n",
    "        elif self.cfg[\"transformers_params\"][\"scheduler\"] == \"cosine\":\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=self.cfg[\"transformers_params\"][\"warmup_ratio\"]\n",
    "                * num_train_steps,\n",
    "                num_training_steps=num_train_steps,\n",
    "                num_cycles=self.cfg[\"transformers_params\"][\"num_cycles\"],\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # ↓ decayする層を選択 & header (decoder) には別の学習率を設定\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if \"model\" not in n],\n",
    "                \"lr\": self.cfg[\"transformers_params\"][\"decoder_lr\"],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        if \"funnel\" in self.cfg[\"model_name\"]:\n",
    "            layers = (\n",
    "                [self.model.embeddings]\n",
    "                + list(self.model.encoder.blocks)\n",
    "                + list(self.model.decoder.layers)\n",
    "            )\n",
    "        else:\n",
    "            layers = [self.model.embeddings] + list(self.model.encoder.layer)\n",
    "        layers.reverse()\n",
    "        lr = self.cfg[\"transformers_params\"][\"encoder_lr\"]\n",
    "        lr_decay = self.cfg[\"transformers_params\"][\"lr_decay_final\"] ** (\n",
    "            1.0 / len(layers)\n",
    "        )\n",
    "        for layer in layers:\n",
    "            optimizer_parameters += [\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p\n",
    "                        for n, p in layer.named_parameters()\n",
    "                        if not any(nd in n for nd in no_decay)\n",
    "                    ],\n",
    "                    \"weight_decay\": self.cfg[\"transformers_params\"][\"weight_decay\"],\n",
    "                    \"lr\": lr,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p\n",
    "                        for n, p in layer.named_parameters()\n",
    "                        if any(nd in n for nd in no_decay)\n",
    "                    ],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                    \"lr\": lr,\n",
    "                },\n",
    "            ]\n",
    "            lr *= lr_decay\n",
    "\n",
    "        optimizer = optim.AdamW(\n",
    "            optimizer_parameters, lr=self.cfg[\"transformers_params\"][\"encoder_lr\"],\n",
    "        )\n",
    "\n",
    "        if self.cfg[\"awp\"] is None:\n",
    "            num_train_steps = self.trainer.estimated_stepping_batches\n",
    "        else:\n",
    "            num_train_steps = (\n",
    "                self.trainer.estimated_stepping_batches\n",
    "                / self.awp_accumulate_grad_batches\n",
    "            )\n",
    "\n",
    "        scheduler = self.get_scheduler(optimizer, num_train_steps)\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    ###############################################################################\n",
    "    # awp -------------------------------------------------------------------------\n",
    "    ###############################################################################\n",
    "    def on_before_optimizer_step(self, optimizer, optimizer_idx):\n",
    "        if self.cfg[\"awp\"] is not None:\n",
    "            self.clip_gradients(\n",
    "                optimizer,\n",
    "                gradient_clip_val=self.awp_max_grad_norm,\n",
    "                gradient_clip_algorithm=None,\n",
    "            )\n",
    "\n",
    "    def _awp_attack_step(self):\n",
    "        e = 1e-6\n",
    "        for name, param in self.named_parameters():\n",
    "            if (\n",
    "                param.requires_grad\n",
    "                and param.grad is not None\n",
    "                and self.adv_param in name\n",
    "            ):\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(param.data, self.backup_eps[name][0]),\n",
    "                        self.backup_eps[name][1],\n",
    "                    )\n",
    "                # param.data.clamp_(*self.backup_eps[name])\n",
    "\n",
    "    def _awp_save(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if (\n",
    "                param.requires_grad\n",
    "                and param.grad is not None\n",
    "                and self.adv_param in name\n",
    "            ):\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps,\n",
    "                    )\n",
    "\n",
    "    def _awp_restore(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:45.297230Z",
     "iopub.status.busy": "2022-11-29T04:28:45.296855Z",
     "iopub.status.idle": "2022-11-29T04:28:45.306238Z",
     "shell.execute_reply": "2022-11-29T04:28:45.305353Z",
     "shell.execute_reply.started": "2022-11-29T04:28:45.297203Z"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1662355265211,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "ISDPW054DobK"
   },
   "outputs": [],
   "source": [
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, cfg, X, y=None):\n",
    "        self.cfg = cfg\n",
    "        if y is None:\n",
    "            self.X = X.values\n",
    "            self.y = torch.zeros(len(self.X), dtype=torch.float32)\n",
    "        else:\n",
    "            self.X = X.values\n",
    "            self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self._prepare_input(self.X[index])\n",
    "        y = self.y[index]\n",
    "        return X, y\n",
    "\n",
    "    def _prepare_input(self, X):\n",
    "        if self.cfg[\"token_cut_head_and_tail\"]:\n",
    "            X = self.cut_head_and_tail(X)\n",
    "        else:\n",
    "            X = self.cfg[\"tokenizer\"].encode_plus(\n",
    "                X,\n",
    "                return_tensors=None,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.cfg[\"tokenizer_params\"][\"max_length\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "        for k, v in X.items():\n",
    "            X[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return X\n",
    "\n",
    "    def cut_head_and_tail(self, text):\n",
    "        # まずは限界を設定せずにトークナイズする\n",
    "        max_len = self.cfg[\"tokenizer_params\"][\"max_length\"]\n",
    "        input_ids = self.cfg[\"tokenizer\"].encode(text)\n",
    "        n_token = len(input_ids)\n",
    "\n",
    "        # トークン数が最大数と同じ場合\n",
    "        if n_token == max_len:\n",
    "            input_ids = input_ids\n",
    "            attention_mask = [1 for _ in range(max_len)]\n",
    "            token_type_ids = [1 for _ in range(max_len)]\n",
    "        # トークン数が最大数より少ない場合\n",
    "        elif n_token < max_len:\n",
    "            pad = [1 for _ in range(max_len - n_token)]\n",
    "            input_ids = input_ids + pad\n",
    "            attention_mask = [1 if n_token > i else 0 for i in range(max_len)]\n",
    "            token_type_ids = [1 if n_token > i else 0 for i in range(max_len)]\n",
    "        # トークン数が最大数より多い場合\n",
    "        else:\n",
    "            harf_len = (max_len - 2) // 2\n",
    "            _input_ids = input_ids[1:-1]\n",
    "            input_ids = [0] + _input_ids[:harf_len] + _input_ids[-harf_len:] + [2]\n",
    "            attention_mask = [1 for _ in range(max_len)]\n",
    "            token_type_ids = [1 for _ in range(max_len)]\n",
    "\n",
    "        d = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "        }\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:46.526538Z",
     "iopub.status.busy": "2022-11-29T04:28:46.525981Z",
     "iopub.status.idle": "2022-11-29T04:28:46.531645Z",
     "shell.execute_reply": "2022-11-29T04:28:46.531090Z",
     "shell.execute_reply.started": "2022-11-29T04:28:46.526508Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformersRegressorInference:\n",
    "    def __init__(self, cfg, weight_path=None):\n",
    "        # tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(cfg[\"model_name\"])\n",
    "        if cfg[\"preprocess\"]:\n",
    "            tokenizer.add_tokens(\"[BR]\", special_tokens=True)\n",
    "        cfg[\"tokenizer\"] = tokenizer\n",
    "\n",
    "        self.model = TransformersModel(cfg)\n",
    "        self.weight_path = weight_path\n",
    "        self.cfg = cfg\n",
    "        self.trainer = Trainer(**self.cfg[\"pl_params\"])\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        preds = []\n",
    "        test_dataset = TableDataset(self.cfg, test_X)\n",
    "        test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_dataset, **self.cfg[\"test_loader\"],\n",
    "        )\n",
    "        preds = self.trainer.predict(\n",
    "            self.model, dataloaders=test_dataloader, ckpt_path=self.weight_path\n",
    "        )\n",
    "        preds = torch.cat(preds, axis=0)\n",
    "        preds = preds.cpu().detach().numpy()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxkQx-RFDobM"
   },
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:47.750066Z",
     "iopub.status.busy": "2022-11-29T04:28:47.749512Z",
     "iopub.status.idle": "2022-11-29T04:28:47.894076Z",
     "shell.execute_reply": "2022-11-29T04:28:47.893449Z",
     "shell.execute_reply.started": "2022-11-29T04:28:47.750038Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1662355266221,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "sqwyL7gnDobN"
   },
   "outputs": [],
   "source": [
    "# read csv\n",
    "train = pd.read_csv(\"../data/input/train.csv\")\n",
    "test = pd.read_csv(\"../data/input/test.csv\")\n",
    "sub = pd.read_csv(\"../data/input/sample_submission.csv\")\n",
    "\n",
    "# split X/y\n",
    "train_X = train[\"full_text\"]\n",
    "train_y = train.drop([\"text_id\", \"full_text\"], axis=1)\n",
    "test_X = test[\"full_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PevYBVQDobO"
   },
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:48.635955Z",
     "iopub.status.busy": "2022-11-29T04:28:48.635281Z",
     "iopub.status.idle": "2022-11-29T04:28:48.640225Z",
     "shell.execute_reply": "2022-11-29T04:28:48.639639Z",
     "shell.execute_reply.started": "2022-11-29T04:28:48.635927Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_fold_valid(skf, cfg, valid_X, valid_y, fold_n):\n",
    "    print(f\"[fold_{fold_n}]\")\n",
    "    seed_everything(cfg[\"general\"][\"seed\"], workers=True)\n",
    "\n",
    "    if use_computed:\n",
    "        valid_preds = joblib.load(f\"../data/preds/valid_{cfg['general']['seed']}_{cfg['general']['save_name']}_{fold_n}.preds\")\n",
    "    else:\n",
    "        model = TransformersRegressorInference(cfg, f\"{cfg['save_weight_folder']}/last_epoch_fold{fold_n}.ckpt\")\n",
    "        valid_preds = model.predict(valid_X)\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    score, scores = mcrmse(valid_y.values, valid_preds)\n",
    "    #print(f\"mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    return valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:49.586619Z",
     "iopub.status.busy": "2022-11-29T04:28:49.585949Z",
     "iopub.status.idle": "2022-11-29T04:28:49.590565Z",
     "shell.execute_reply": "2022-11-29T04:28:49.589918Z",
     "shell.execute_reply.started": "2022-11-29T04:28:49.586593Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_fold_test(cfg, test_X, fold_n):\n",
    "    print(f\"[fold_{fold_n}]\")\n",
    "    seed_everything(cfg[\"general\"][\"seed\"], workers=True)\n",
    "\n",
    "    model = TransformersRegressorInference(cfg, f\"{cfg['save_weight_folder']}/last_epoch_fold{fold_n}.ckpt\")\n",
    "    test_preds = model.predict(test_X)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:50.090455Z",
     "iopub.status.busy": "2022-11-29T04:28:50.090063Z",
     "iopub.status.idle": "2022-11-29T04:28:50.100461Z",
     "shell.execute_reply": "2022-11-29T04:28:50.099781Z",
     "shell.execute_reply.started": "2022-11-29T04:28:50.090427Z"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1662355265201,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "R_-bDv4rDoau",
    "outputId": "e5532017-d235-4faa-d869-38e38fe4d3d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random seed setting\n",
    "seed_everything(cfg1[\"general\"][\"seed\"], workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:50.971434Z",
     "iopub.status.busy": "2022-11-29T04:28:50.970475Z",
     "iopub.status.idle": "2022-11-29T04:28:50.974429Z",
     "shell.execute_reply": "2022-11-29T04:28:50.973723Z",
     "shell.execute_reply.started": "2022-11-29T04:28:50.971403Z"
    }
   },
   "outputs": [],
   "source": [
    "use_computed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize weights only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:28:52.623900Z",
     "iopub.status.busy": "2022-11-29T04:28:52.623324Z",
     "iopub.status.idle": "2022-11-29T04:29:20.866296Z",
     "shell.execute_reply": "2022-11-29T04:29:20.865437Z",
     "shell.execute_reply.started": "2022-11-29T04:28:52.623876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "\n",
      "simple_mean: mcrmse_score:0.4395834204129965, mcrmse_scores:[0.46872539000118907, 0.4483134018254309, 0.394330463024263, 0.4428740386945851, 0.4470923958632945, 0.436164833069216]\n",
      "cfg_0: mcrmse_score:0.44640483963315886, mcrmse_scores:[0.47736600030859094, 0.45743326943302653, 0.4035178557604888, 0.4472353210330416, 0.45255893482328374, 0.44031765644052184]\n",
      "cfg_1: mcrmse_score:0.44796350194232004, mcrmse_scores:[0.47839677325350755, 0.4500609600486165, 0.40672602294122245, 0.4542348897733609, 0.456231321472265, 0.4421310441649481]\n",
      "cfg_2: mcrmse_score:0.4518655966614231, mcrmse_scores:[0.47610925836151624, 0.466663764963195, 0.403818631302194, 0.45068034843863386, 0.4641070886183531, 0.44981448828464643]\n",
      "cfg_3: mcrmse_score:0.44576787552777325, mcrmse_scores:[0.47463702963341237, 0.45031524767192027, 0.398496345404305, 0.4497555901222513, 0.4560446593306536, 0.4453583810040973]\n",
      "cfg_4: mcrmse_score:0.44400730227612345, mcrmse_scores:[0.4749378623469204, 0.4534323983125786, 0.3995082979821595, 0.4459138344145677, 0.45244755950075377, 0.43780386109976094]\n",
      "cfg_5: mcrmse_score:0.44392140697254895, mcrmse_scores:[0.4721428489273832, 0.4528822484170729, 0.4005746607697104, 0.4487866420005934, 0.4496669119485282, 0.43947512977200537]\n",
      "cfg_6: mcrmse_score:0.4419459502992041, mcrmse_scores:[0.46944567439592527, 0.44815550236846435, 0.39666043195285317, 0.44328323409390624, 0.4521334834824832, 0.441997375501592]\n",
      "cfg_7: mcrmse_score:0.4499384789052617, mcrmse_scores:[0.4832301623008842, 0.46116951162349856, 0.40001081640003733, 0.45274576191715943, 0.4570479583191143, 0.4454266628708763]\n",
      "cfg_8: mcrmse_score:0.4505933852236725, mcrmse_scores:[0.48312369069547, 0.45802994725262536, 0.40278786982165704, 0.4545187638487608, 0.4592743170145983, 0.44582572270892296]\n",
      "cfg_9: mcrmse_score:0.45075812446612246, mcrmse_scores:[0.4807777676642173, 0.45522515691908055, 0.4020169725719855, 0.4524570616084957, 0.4638037632297645, 0.45026802480319095]\n",
      "cfg_10: mcrmse_score:0.44768794380412863, mcrmse_scores:[0.483815811352151, 0.45392013517515795, 0.4025646170271289, 0.4490566737607938, 0.45507680072263595, 0.44169362478690427]\n",
      "cfg_11: mcrmse_score:0.4521549494628317, mcrmse_scores:[0.4846728656918563, 0.4606417357696474, 0.3975023961560663, 0.45532644259006655, 0.4632851607942896, 0.4515010957750641]\n",
      "cfg_12: mcrmse_score:0.4483251269848661, mcrmse_scores:[0.4858544435159419, 0.45353203402148096, 0.3984135032141631, 0.45120899703110384, 0.4562922220443154, 0.44464956208219136]\n",
      "cfg_13: mcrmse_score:0.4464640741056058, mcrmse_scores:[0.47836937090551207, 0.45911133795152215, 0.40175991927578925, 0.44707565242355934, 0.4499893331182982, 0.44247883095895346]\n",
      "optimized_corr:0.4658483192462376\n",
      "weights:[0.020794377644139397, 1.4540148086430872e-06, 0.22229675561624507, 0.0839062763723684, 0.018079382720561855, 0.04387889294745319, 0.24448269417629448, 0.1728300542024067, 0.01905049721588182, 0.04158557161093663, 0.09943720095552375, 0.004196612881353971, 0.018146145029049425, 8.547570479911941e-05]\n",
      "optimized_corr:0.4448217473760699\n",
      "weights:[0.0008033460835426035, 0.17876702211953555, 0.00020621620789845453, 0.10839078094835611, 0.01765607095311494, 0.0357620355906627, 0.1962294835169237, 0.02781302102767725, 1.939983540602651e-05, 0.20473303251884536, 0.005735223870963101, 1.0918359430096356e-05, 0.21346295206271768, 2.025933588686765e-05]\n",
      "optimized_corr:0.39301809004941435\n",
      "weights:[0.11873254062861549, 0.0007806533232435266, 0.08086629085198604, 0.013001917855695478, 0.0006560466208182063, 0.08719757599216127, 0.1707527009411306, 0.08616987206867666, 0.0, 0.08559255830135698, 0.027395413506408076, 0.16418153386395135, 0.16447420726380613, 0.002581286062394963]\n",
      "optimized_corr:0.4403498304066884\n",
      "weights:[0.16342813983914511, 0.0009120594833139566, 0.24243165124031207, 0.24845414255274634, 0.004986136987418998, 0.00019354194386438073, 0.08864586703420267, 0.08843134342593112, 0.02986565266598037, 0.02210485670334162, 0.025032899577640606, 0.00032407683055994815, 0.07321183077868898, 0.0012837321434504179]\n",
      "optimized_corr:0.4445283003661162\n",
      "weights:[0.10624438595037848, 0.10458341748890787, 0.10907317197314598, 8.846347142147073e-05, 1.2798234418995454e-05, 0.03845847968791441, 0.15082138546437066, 0.14449287225450047, 0.011329623664407453, 0.0006212415877345306, 0.12342757852863315, 0.0063998313611998234, 0.08560002484879982, 0.10622572013686056]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_corr:0.43486146708691004\n",
      "weights:[0.16943879019953695, 0.13374667256725653, 0.060166471923693884, 0.05900960857628819, 0.12103765465657723, 0.12145929672266456, 0.04568238298165066, 0.0034841521836587895, 0.006808762724582817, 1.8408533833407225e-05, 0.11360649087507294, 0.00010132056618423452, 0.047515920926041136, 0.11481333233747368]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n",
      "\n",
      "simple_mean: mcrmse_score:0.4452882493930122, mcrmse_scores:[0.4739343422767327, 0.43376635437729216, 0.4078216219628406, 0.46127071379410706, 0.45972364668874494, 0.435212817258356]\n",
      "cfg_0: mcrmse_score:0.4591567243002456, mcrmse_scores:[0.49545116605691003, 0.44508254136252245, 0.42248581875415736, 0.4721200765252766, 0.470575918965479, 0.4492248241371281]\n",
      "cfg_1: mcrmse_score:0.4501004886269688, mcrmse_scores:[0.4794066833124652, 0.43651016340763094, 0.41523658292584614, 0.46139840296625045, 0.46731349803980354, 0.44073760110981597]\n",
      "cfg_2: mcrmse_score:0.4570095519387465, mcrmse_scores:[0.4806723645246442, 0.4454368570035867, 0.41548546576200046, 0.469845180271951, 0.4764595068719748, 0.454157937198322]\n",
      "cfg_3: mcrmse_score:0.4494251824734414, mcrmse_scores:[0.47927391733913083, 0.4341051645923393, 0.41139067713698285, 0.4665578025512364, 0.4657478328850537, 0.4394757003359052]\n",
      "cfg_4: mcrmse_score:0.4513923575817543, mcrmse_scores:[0.4829377182359557, 0.43899788702306225, 0.4148507045933215, 0.46724832983758924, 0.4640935207610084, 0.44022598503958893]\n",
      "cfg_5: mcrmse_score:0.4484459410245815, mcrmse_scores:[0.47805360879001935, 0.4379954072471864, 0.40948062427068627, 0.46459497398682076, 0.4618885266028861, 0.4386625052498901]\n",
      "cfg_6: mcrmse_score:0.44762133151451383, mcrmse_scores:[0.4749830822351564, 0.4359562800867287, 0.4104665069203125, 0.4639968529781211, 0.463984733227765, 0.43634053363899933]\n",
      "cfg_7: mcrmse_score:0.45541209517604747, mcrmse_scores:[0.48958263646519146, 0.4412954281739044, 0.4175636147074807, 0.4719983810762932, 0.4691267756217471, 0.44290573501166813]\n",
      "cfg_8: mcrmse_score:0.45364297501323025, mcrmse_scores:[0.48510413630379395, 0.44503879553880527, 0.4155274989187876, 0.4668495667041172, 0.4701946632070312, 0.4391431894068462]\n",
      "cfg_9: mcrmse_score:0.45636642638750763, mcrmse_scores:[0.48204235593566985, 0.4437564784195446, 0.4162366679396298, 0.47263313881416785, 0.4787646425265323, 0.44476527468950183]\n",
      "cfg_10: mcrmse_score:0.4523263627902025, mcrmse_scores:[0.4804590053980467, 0.4430358984856402, 0.41184771592026603, 0.4680189249873153, 0.4668243937099365, 0.44377223824001044]\n",
      "cfg_11: mcrmse_score:0.4539614039396884, mcrmse_scores:[0.48503605518266746, 0.44283478106982327, 0.4094293722522921, 0.47067132770380377, 0.47062019633787533, 0.4451766910916685]\n",
      "cfg_12: mcrmse_score:0.4547795363769076, mcrmse_scores:[0.4875514808442886, 0.44619592434798594, 0.4104873100000719, 0.46942343008525655, 0.4705240251481081, 0.4444950478357343]\n",
      "cfg_13: mcrmse_score:0.4561982087043377, mcrmse_scores:[0.491855117550744, 0.4432972277146879, 0.41981284744180464, 0.4707393630313468, 0.4666866355716095, 0.4447980609158333]\n",
      "optimized_corr:0.4707529806943643\n",
      "weights:[0.0004982163308048529, 0.07728412719502212, 0.1844356133109636, 0.10391005088849448, 0.00017637960267030998, 0.08518126451915942, 0.11778172693451247, 0.0757321990096112, 0.09664995571607984, 0.14608348042399938, 0.10930437529875109, 0.005339468522343457, 0.0014340181256803485, 0.0004035828711976381]\n",
      "optimized_corr:0.43163951128307515\n",
      "weights:[0.001338395122810074, 0.13065171590664104, 0.0015933670968689487, 0.3124266019276608, 0.003912511432377563, 0.1378070257882804, 0.11977163258993406, 0.23955956595880845, 0.0027970586277950345, 0.028024753817822726, 0.00010521746921111234, 0.022686990762443425, 0.00044965926379183325, 0.0008918225132627507]\n",
      "optimized_corr:0.405803602170761\n",
      "weights:[0.044586664633045954, 5.0009960520814756e-05, 0.053501778881302434, 0.10527636052307529, 0.011488566251309134, 0.049221030857099626, 0.22396699105827006, 0.04809173991555711, 0.026352241366021288, 8.400614038131086e-06, 0.11378100206056388, 0.22718755232316284, 0.09948670666901138, 0.0007380674216797027]\n",
      "optimized_corr:0.45894423899041276\n",
      "weights:[0.00041494623838326476, 0.41035843922299464, 0.1566238968032263, 0.03918002408929615, 0.005110240604519173, 0.0014297519624313, 0.08964038716358788, 5.5244146867134206e-05, 0.17212304305315862, 7.001556799647001e-05, 0.05118185627117183, 0.00026844199775297823, 0.0637541864969838, 0.013495000436022385]\n",
      "optimized_corr:0.45846974055833034\n",
      "weights:[0.013039803642068842, 0.027284223028823523, 0.08149966556503768, 0.23521003822095046, 0.14884522419334068, 0.17558547856055445, 0.055333897491971255, 0.015274877950017926, 0.02556415763058273, 6.759631222679182e-05, 0.11862563630470019, 0.029511397537849447, 0.022277136204491097, 0.057852569003805]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_corr:0.4324147648942163\n",
      "weights:[1.4970560037667958e-05, 0.06763704300589476, 0.001027854034697643, 0.3115374448641833, 6.395914093446585e-05, 0.023857621966075562, 0.1024431801522725, 0.04306375321856726, 0.24245411023215943, 4.595107949016973e-06, 0.005758627164820777, 0.0732844245381303, 0.09683993379759111, 0.04283097795899114]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.44897154114473464, mcrmse_scores:[0.4833268370763778, 0.4528480897197775, 0.4090392770053821, 0.4340088423627159, 0.46491287880428556, 0.4496933218998687]\n",
      "cfg_0: mcrmse_score:0.45598181902917706, mcrmse_scores:[0.49275559121976914, 0.45920548350873497, 0.41902340673734306, 0.4404931566534003, 0.46747934262175905, 0.4569339334340556]\n",
      "cfg_1: mcrmse_score:0.4607981980510454, mcrmse_scores:[0.49793969719573805, 0.4656664558472726, 0.4198178404521915, 0.44341782916535966, 0.4761875320384251, 0.461759833607285]\n",
      "cfg_2: mcrmse_score:0.46586662530580303, mcrmse_scores:[0.5048782083583988, 0.46431786827989324, 0.4281608256036924, 0.45237744861036566, 0.48481347881348524, 0.4606519221689827]\n",
      "cfg_3: mcrmse_score:0.4526238439788073, mcrmse_scores:[0.48634174180172873, 0.4580202636777276, 0.41096537377691544, 0.437138527853342, 0.4689966441645442, 0.4542805125985855]\n",
      "cfg_4: mcrmse_score:0.4540362309041926, mcrmse_scores:[0.48805045893386967, 0.4570092297762306, 0.4175634038858818, 0.43677881905709975, 0.46937812063948753, 0.45543735313258615]\n",
      "cfg_5: mcrmse_score:0.45212575049040243, mcrmse_scores:[0.48789419903855064, 0.45479066606714724, 0.4128193391795571, 0.436223749765252, 0.4670813533060304, 0.45394519558587726]\n",
      "cfg_6: mcrmse_score:0.4508383858434246, mcrmse_scores:[0.48604685099338796, 0.45688582185527854, 0.40741067862627744, 0.4363123729413935, 0.46689838671547657, 0.45147620392873333]\n",
      "cfg_7: mcrmse_score:0.457766845528432, mcrmse_scores:[0.48996483316131584, 0.45844819888073535, 0.4163832756789711, 0.4505268949962704, 0.4738292144603142, 0.4574486559929851]\n",
      "cfg_8: mcrmse_score:0.459711196621277, mcrmse_scores:[0.49474073933742185, 0.46394110479405626, 0.41184883907581826, 0.4486655718791663, 0.4809069369352002, 0.45816398770599887]\n",
      "cfg_9: mcrmse_score:0.45802752747901704, mcrmse_scores:[0.49731813917326023, 0.4631730125409969, 0.41403432336704105, 0.4449830102982087, 0.4727264062412667, 0.4559302732533286]\n",
      "cfg_10: mcrmse_score:0.45607528766244165, mcrmse_scores:[0.4952806327648468, 0.4576899734085342, 0.4125954464292958, 0.43941559476867253, 0.4742363908284833, 0.4572336877748173]\n",
      "cfg_11: mcrmse_score:0.4593321957360091, mcrmse_scores:[0.4963357170748607, 0.464884535273588, 0.4165907125753918, 0.44088695007078776, 0.4765440266445968, 0.4607512327768294]\n",
      "cfg_12: mcrmse_score:0.4618683357799833, mcrmse_scores:[0.5028906959607108, 0.4630045735007018, 0.4164166442054479, 0.4424030131445639, 0.4798333030609083, 0.46666178480756776]\n",
      "cfg_13: mcrmse_score:0.45843066960849255, mcrmse_scores:[0.4905329872646948, 0.46073863319842584, 0.4236947999435484, 0.4420706186409205, 0.4729181669608831, 0.46062881164248237]\n",
      "optimized_corr:0.48139572013143317\n",
      "weights:[0.019617653929853082, 8.573512129231105e-05, 0.03917697778885086, 0.2401090481284332, 0.026823336482055073, 2.8385308349419423e-05, 0.006599180095825151, 0.23666092963094124, 0.13892818769444204, 0.16604610947242052, 0.0003068831875521193, 0.03645241810302269, 0.0011440053271176654, 0.08339111761011]\n",
      "optimized_corr:0.4515238987843425\n",
      "weights:[0.08202100087045422, 0.018366820818134705, 0.09234718621263133, 0.10060928600252395, 0.03593993831471409, 0.013688016084901292, 0.18077415691837084, 0.17510427327052736, 0.014692685298883831, 0.045074838884131024, 0.1742391576578891, 0.023570106244170774, 0.0014225371362410139, 0.0484300132308948]\n",
      "optimized_corr:0.4066214091371982\n",
      "weights:[0.0010397971109539984, 0.006580510327470743, 0.004020750247235626, 0.03890888857788402, 0.00010981538442512664, 0.017528010846414595, 0.16503258082156547, 0.05795122356466109, 0.25519970818662996, 0.13617605301901686, 0.19768662825823002, 0.06730602693198201, 0.023531435310792992, 0.027446240660828014]\n",
      "optimized_corr:0.43233326819111306\n",
      "weights:[0.1462938787703965, 7.302023391823073e-05, 4.6565624153614764e-05, 0.07611184421078318, 0.11286027950252292, 0.16315374148292006, 0.12839264843544865, 2.792149436194867e-05, 1.647902724013072e-05, 0.09442852747452347, 0.17585526004082858, 0.0860290198788344, 0.003762640436320158, 0.009210591916153192]\n",
      "optimized_corr:0.462651394530155\n",
      "weights:[0.21969029261199124, 0.0022570536915115288, 0.0, 0.03959853301958967, 0.05270740199030638, 0.1388419517999938, 0.113602586012017, 0.0636940050593994, 0.010468268846883302, 0.21449022278335883, 0.0696049242214764, 0.015004131114427197, 0.038718408450001324, 0.023484830495223943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_corr:0.44728712726079445\n",
      "weights:[0.08888808381347768, 4.9618361594857475e-05, 0.18313871578124097, 0.021670576568545104, 0.004412059044858941, 0.029526460751643044, 0.10597751197754418, 0.05689957492990513, 0.000702991898176371, 0.2574434987518226, 0.18264698545546953, 0.04072958882115897, 0.0008597315897575473, 0.0297516750495046]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n",
      "\n",
      "simple_mean: mcrmse_score:0.44530525169450685, mcrmse_scores:[0.4664746843174213, 0.4322829172672516, 0.4141041594223839, 0.4496427099156052, 0.4809143321419051, 0.4284127071024743]\n",
      "cfg_0: mcrmse_score:0.4546369433395701, mcrmse_scores:[0.4786551465687863, 0.44320550067310543, 0.42163403904173097, 0.4534669652670811, 0.4865551089312972, 0.4443048995554197]\n",
      "cfg_1: mcrmse_score:0.45042563007718556, mcrmse_scores:[0.4660897480364336, 0.4373463190649996, 0.41801434849792535, 0.4545812768035626, 0.4903899016611934, 0.4361321863989987]\n",
      "cfg_2: mcrmse_score:0.45579571088171417, mcrmse_scores:[0.47435089142660203, 0.44522336659534023, 0.42129983954035355, 0.46141449307764115, 0.49318820793316054, 0.4392974667171875]\n",
      "cfg_3: mcrmse_score:0.45217216145887673, mcrmse_scores:[0.47916371639949384, 0.438520755551073, 0.4164349596284445, 0.4600609179768817, 0.4876288898203114, 0.43122372937705616]\n",
      "cfg_4: mcrmse_score:0.4494843434855242, mcrmse_scores:[0.4748800706978306, 0.43535515606088465, 0.417091522623616, 0.4494455261610361, 0.4870635451805069, 0.4330702401892704]\n",
      "cfg_5: mcrmse_score:0.4491996685075883, mcrmse_scores:[0.47308664890496493, 0.4392901316639987, 0.4184433790141843, 0.45098352998371455, 0.4817978346197237, 0.43159648685894375]\n",
      "cfg_6: mcrmse_score:0.4484264072321977, mcrmse_scores:[0.47025736459751416, 0.4333543468293386, 0.41595432863086806, 0.4548926924333342, 0.4872833444055645, 0.4288163664965662]\n",
      "cfg_7: mcrmse_score:0.4528641391697404, mcrmse_scores:[0.47482037158545704, 0.4357546506254134, 0.4202424221955821, 0.4538836338553317, 0.4932929412598689, 0.4391908154967891]\n",
      "cfg_8: mcrmse_score:0.4506021574297823, mcrmse_scores:[0.46962583027881966, 0.43858841767768375, 0.42120077133048534, 0.4536497490987997, 0.48567941909842804, 0.4348687570944778]\n",
      "cfg_9: mcrmse_score:0.45247780573228336, mcrmse_scores:[0.47039646400094526, 0.43478393492270345, 0.42080619211322323, 0.4621164620553779, 0.49470069749412293, 0.43206308380732744]\n",
      "cfg_10: mcrmse_score:0.4537649439464382, mcrmse_scores:[0.48014852888361004, 0.4384486382342658, 0.4231174895917592, 0.45802568578381686, 0.48472795062832696, 0.43812137055684985]\n",
      "cfg_11: mcrmse_score:0.45749360448316545, mcrmse_scores:[0.48362869336215464, 0.4475152829967566, 0.4205478651921329, 0.4635892590709778, 0.4938478866539192, 0.4358326396230514]\n",
      "cfg_12: mcrmse_score:0.4530520747822933, mcrmse_scores:[0.4765937209815579, 0.44056194513709307, 0.4219944291594359, 0.4588581292788522, 0.48410745234413755, 0.4361967717926832]\n",
      "cfg_13: mcrmse_score:0.45532558455675304, mcrmse_scores:[0.47869083112250216, 0.440257304576528, 0.4251748264338545, 0.45288159374341547, 0.4909443414396429, 0.4440046100245754]\n",
      "optimized_corr:0.462933607270851\n",
      "weights:[0.15112380382877122, 0.06309675673363443, 0.20786254898458512, 0.06923420780517456, 0.00014997773444001329, 0.0003066045049197924, 2.7789601040759115e-05, 0.028076664296088752, 0.17278296600531318, 0.21462124036875863, 0.01181008693471268, 0.0170739820937015, 0.056821044194969056, 0.006702466740445254]\n",
      "optimized_corr:0.4292007997397021\n",
      "weights:[0.0008282372929394942, 0.0677277760326341, 0.0005749345985697455, 0.024559949071176368, 0.13782141610095305, 0.01076835380540201, 0.009438234105576029, 0.2268583985872522, 0.01973584351949912, 0.3490387445558838, 0.09495007260179011, 0.0020688935004853784, 0.06151048667458191, 0.0005674687475621955]\n",
      "optimized_corr:0.41353464467496337\n",
      "weights:[0.11787525051108222, 0.08619803820673773, 0.14243835746397598, 0.018453306175639447, 0.06261778207526172, 0.006797207052169762, 0.22404433192337014, 0.06912746143701856, 0.05092544296366676, 0.042467118526426574, 0.05641420822457474, 0.0936728523226559, 0.029036808223988915, 0.001177416143524488]\n",
      "optimized_corr:0.4480161910835315\n",
      "weights:[0.10560495202013456, 0.20036848216666314, 0.058947372040854, 0.000844742546492625, 0.25673259335155385, 0.020573244537695996, 3.0615059829514204e-05, 0.01525345395841722, 0.16872881677032447, 0.0016491110730920784, 0.03769061550082543, 0.004386303624967714, 0.002950901313886317, 0.1251882169542894]\n",
      "optimized_corr:0.4789882576842538\n",
      "weights:[0.1266458289101759, 9.736910288722037e-05, 0.09261147857539809, 0.07825030208970693, 0.0008663579197784529, 0.11063602919747095, 0.011213799324698723, 0.00010321657502756511, 0.13175890044820426, 0.047553273266613724, 0.18540586505980722, 0.001066954936274219, 0.21124044236898876, 0.00240889699766855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_corr:0.42592135602756714\n",
      "weights:[5.620026290888201e-08, 0.00795166705088397, 0.07510984112638885, 0.048493120669639594, 0.061172109085333826, 0.05735640740582673, 0.12432578773188019, 0.00012814615696493822, 0.17697768447306483, 0.22016758945520754, 0.005869683249118768, 0.19486322791323396, 0.023698197146616785, 1.745650536220673e-05]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "\n",
      "simple_mean: mcrmse_score:0.4418603842045263, mcrmse_scores:[0.4650295479620753, 0.4221627827221631, 0.4122575878243325, 0.4502636911368272, 0.462159029038597, 0.43928966654316226]\n",
      "cfg_0: mcrmse_score:0.4517432058281796, mcrmse_scores:[0.47790252081984874, 0.42759786637027475, 0.4232340058467752, 0.4588235932990546, 0.47044895824130306, 0.45245229039182144]\n",
      "cfg_1: mcrmse_score:0.4474640998250639, mcrmse_scores:[0.47378012786355067, 0.42520154386126247, 0.41987411796431484, 0.4547621280443761, 0.4684081530656485, 0.44275852815123135]\n",
      "cfg_2: mcrmse_score:0.45474245588007145, mcrmse_scores:[0.47896108741292504, 0.4353564752441213, 0.419943114849705, 0.46247888795965925, 0.47652757759760483, 0.4551875922164135]\n",
      "cfg_3: mcrmse_score:0.4509786768557819, mcrmse_scores:[0.4730383834428002, 0.43105428880088453, 0.420076257551725, 0.45826358489383207, 0.47439672919999937, 0.44904281724545003]\n",
      "cfg_4: mcrmse_score:0.4456061886395044, mcrmse_scores:[0.47043601950456565, 0.4247738142780557, 0.41727188594703873, 0.45439039982591134, 0.4648526529903222, 0.4419123592911326]\n",
      "cfg_5: mcrmse_score:0.44620144447381155, mcrmse_scores:[0.4698193252581817, 0.42705557777811237, 0.4181404899501098, 0.4510418720818392, 0.46947826224806927, 0.4416731395265565]\n",
      "cfg_6: mcrmse_score:0.44691575269568035, mcrmse_scores:[0.4699666983768682, 0.42729950225540597, 0.4157008738459265, 0.45395279309038594, 0.47199928788004003, 0.4425753607254553]\n",
      "cfg_7: mcrmse_score:0.4484701966852856, mcrmse_scores:[0.4802683470475302, 0.42515595505645987, 0.42013375081130566, 0.45779605292499714, 0.4633409047551504, 0.44412616951627076]\n",
      "cfg_8: mcrmse_score:0.45110633947676004, mcrmse_scores:[0.4732825455309148, 0.4332424346578869, 0.4230107182419888, 0.45720935161827336, 0.4729457470342629, 0.4469472397772333]\n",
      "cfg_9: mcrmse_score:0.4513519586781976, mcrmse_scores:[0.47928169947921967, 0.43032278735371293, 0.4168310035407983, 0.46058171125738556, 0.4716657762526188, 0.4494287741854506]\n",
      "cfg_10: mcrmse_score:0.44983047504576473, mcrmse_scores:[0.47830534113223944, 0.43520063255908836, 0.4173369624250953, 0.45482813481806617, 0.46812010582163993, 0.4451916735184597]\n",
      "cfg_11: mcrmse_score:0.45355228487521243, mcrmse_scores:[0.4753213219942976, 0.43419730323643185, 0.4182405968198867, 0.463000102485932, 0.4769070356517753, 0.45364734906295123]\n",
      "cfg_12: mcrmse_score:0.45285619623094414, mcrmse_scores:[0.476267202138535, 0.4372230428527562, 0.41884593345454235, 0.46088482147933335, 0.4701093959054172, 0.453806781555081]\n",
      "cfg_13: mcrmse_score:0.45007391324654417, mcrmse_scores:[0.47656555477175067, 0.42668621938517953, 0.4234716260023194, 0.4582788618370694, 0.467043696258952, 0.44839752122399396]\n",
      "optimized_corr:0.4630422370400779\n",
      "weights:[0.0010919494115109911, 0.16843899687589386, 0.11942785536225414, 0.0001306592899880611, 0.08624116625467354, 0.0001850928559953102, 0.002506656673364265, 0.0006329946096786554, 0.2453396039464273, 0.062456690433748074, 0.0003480589313648423, 0.1403647712977315, 0.11095709273083515, 0.06847941259784868]\n",
      "optimized_corr:0.4198013844266805\n",
      "weights:[0.14081112143339314, 0.2269102676467047, 0.04603648114779155, 0.0006742624294787476, 0.0019969730405064497, 0.015342254839446734, 0.00010857119086045148, 0.10210873218423189, 0.025001619690267974, 0.093618852788732, 0.0, 0.09890943699640631, 0.0010041421714792288, 0.2533091669614709]\n",
      "optimized_corr:0.41049132232162144\n",
      "weights:[0.002132963633862368, 0.10550250165622371, 0.1791336292982681, 0.0001016281665415247, 6.761500313777523e-05, 3.3506427736896277e-06, 4.4412257987207926e-05, 0.1238570166105661, 0.00018154967975907773, 0.12995546151318532, 0.11592579180605468, 0.1794076323583518, 0.15866027953124368, 0.004562360158666512]\n",
      "optimized_corr:0.44874276893100856\n",
      "weights:[0.05858047947488354, 0.30803299289169417, 0.1028574352485147, 0.0001738435002913235, 0.02694832526239562, 0.11971446243979206, 0.005507129535269896, 0.059604574089447, 0.048013383422056244, 0.008456886444994354, 0.2559417193196364, 0.0, 0.0006281610649147321, 0.008937473991606455]\n",
      "optimized_corr:0.45795283346461807\n",
      "weights:[0.0038106462656754617, 0.12726962935894326, 0.11698515407252202, 0.010334661561293142, 0.035985753586321764, 0.00822353574760342, 0.019958161843694144, 0.32248288633518407, 0.0, 0.12004056315461198, 0.2082795218843856, 0.0015944715164480155, 0.03362435409827885, 0.002982811487543712]\n",
      "optimized_corr:0.4371422863606937\n",
      "weights:[0.011653989390790646, 0.24580970891612186, 0.021073900632674843, 0.0014452684893752955, 4.782737432375956e-05, 0.11991119965125507, 0.053009299150526074, 0.16193453551897985, 0.048083908029020184, 0.09589238484237161, 0.20492115245368459, 0.03914457416988559, 0.0013780534535324522, 0.0005055030149773443]\n",
      "\n",
      "cohesion averaged_weights:[0.0386252  0.06178141 0.15463995 0.09945805 0.02629405 0.02591605\n",
      " 0.07427961 0.10278657 0.13455024 0.12615862 0.04424132 0.04068545\n",
      " 0.03770046 0.03181241]\n",
      "syntax averaged_weights:[0.04516042 0.12448472 0.02815164 0.10933218 0.03946538 0.04267354\n",
      " 0.10126442 0.1542888  0.01244932 0.14409804 0.05500593 0.02944927\n",
      " 0.05556996 0.06064375]\n",
      "vocabulary averaged_weights:[0.05687344 0.03982234 0.09199216 0.03514842 0.01498797 0.03214944\n",
      " 0.1567682  0.07703946 0.06653179 0.07883992 0.10224061 0.14635112\n",
      " 0.09503789 0.00730107]\n",
      "phraseology averaged_weights:[0.09486448 0.183949   0.11218138 0.07295292 0.08132752 0.06101295\n",
      " 0.06244333 0.03267451 0.08374947 0.02534188 0.10914047 0.01820157\n",
      " 0.02886154 0.031623  ]\n",
      "grammar averaged_weights:[0.09388619 0.05229834 0.08003389 0.0726964  0.04768351 0.09434909\n",
      " 0.07018597 0.10920957 0.03582419 0.07655458 0.14106871 0.01071536\n",
      " 0.07829207 0.03859097]\n",
      "conventions averaged_weights:[0.05399918 0.09103894 0.06810336 0.0884312  0.03734672 0.0704222\n",
      " 0.08628763 0.05310203 0.09500549 0.1147053  0.10256059 0.06962463\n",
      " 0.03405837 0.03758379]\n"
     ]
    }
   ],
   "source": [
    "fold_list = range(cfg1[\"general\"][\"n_splits\"])\n",
    "weights_list = [[] for _ in range(6)]\n",
    "skf = MultilabelStratifiedKFold(\n",
    "    n_splits=cfg1[\"general\"][\"n_splits\"], shuffle=True, random_state=cfg1[\"general\"][\"seed\"]\n",
    ")\n",
    "for j, fold_n in enumerate(fold_list):\n",
    "    preds_list = []\n",
    "    _, valid_indices = list(skf.split(train_X, train_y))[fold_n]\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        valid_preds = one_fold_valid(skf, cfg, valid_X_cv, valid_y_cv, fold_n)\n",
    "        preds_list.append(valid_preds)\n",
    "        del valid_preds\n",
    "        gc.collect()\n",
    "\n",
    "    score, scores = mcrmse(valid_y_cv.values, np.mean(preds_list, axis=0))\n",
    "    print()\n",
    "    print(f\"simple_mean: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    for i, p in enumerate(preds_list):\n",
    "        score, scores = mcrmse(valid_y_cv.values, p)\n",
    "        print(f\"cfg_{i}: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    preds_list = np.array(preds_list)\n",
    "    cohesion = preds_list[:, :, 0]\n",
    "    syntax = preds_list[:, :, 1]\n",
    "    vocabulary = preds_list[:, :, 2]\n",
    "    phraseology = preds_list[:, :, 3]\n",
    "    grammar = preds_list[:, :, 4]\n",
    "    conventions = preds_list[:, :, 5]\n",
    "    target_list = [cohesion, syntax, vocabulary, phraseology, grammar, conventions]\n",
    "    \n",
    "    for t_idx, target in enumerate(target_list):\n",
    "\n",
    "        def f(x):\n",
    "            pred = np.zeros_like(target[0])\n",
    "            for i, p in enumerate(target):\n",
    "                pred += p * x[i]\n",
    "            score = metrics.mean_squared_error(\n",
    "                valid_y_cv.values[:, t_idx], pred, squared=False\n",
    "            )\n",
    "            return score\n",
    "\n",
    "        init_state = np.ones((len(target))) / len(target)\n",
    "        bounds = [(0.0, 1.0)] * len(target)\n",
    "        result = minimize(f, init_state, method=\"Nelder-Mead\", bounds=bounds)\n",
    "        print(f\"optimized_corr:{result['fun']}\")\n",
    "\n",
    "        weights = [[0] for _ in range(len(target))]\n",
    "        for i in range(len(target)):\n",
    "            weights[i] = result[\"x\"][i]\n",
    "        weights_list[t_idx].append(weights)\n",
    "        print(f\"weights:{weights}\")\n",
    "\n",
    "avg_weights_cohesion = np.mean(weights_list[0], axis=0)\n",
    "avg_weights_syntax = np.mean(weights_list[1], axis=0)\n",
    "avg_weights_vocabulary = np.mean(weights_list[2], axis=0)\n",
    "avg_weights_phraseology = np.mean(weights_list[3], axis=0)\n",
    "avg_weights_grammar = np.mean(weights_list[4], axis=0)\n",
    "avg_weights_conventions = np.mean(weights_list[5], axis=0)\n",
    "\n",
    "print()\n",
    "print(f\"cohesion averaged_weights:{avg_weights_cohesion}\")\n",
    "print(f\"syntax averaged_weights:{avg_weights_syntax}\")\n",
    "print(f\"vocabulary averaged_weights:{avg_weights_vocabulary}\")\n",
    "print(f\"phraseology averaged_weights:{avg_weights_phraseology}\")\n",
    "print(f\"grammar averaged_weights:{avg_weights_grammar}\")\n",
    "print(f\"conventions averaged_weights:{avg_weights_conventions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:29:20.867632Z",
     "iopub.status.busy": "2022-11-29T04:29:20.867427Z",
     "iopub.status.idle": "2022-11-29T04:29:20.881032Z",
     "shell.execute_reply": "2022-11-29T04:29:20.880025Z",
     "shell.execute_reply.started": "2022-11-29T04:29:20.867613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghts/deberta_v3_base_4096_reinit: mean_weight -> 0.0639014854117706\n",
      "ghts/deberta_large_512_reinit: mean_weight -> 0.09222912608366358\n",
      "ghts/muppet_large_512_reinit: mean_weight -> 0.08918373059037628\n",
      "ghts/deberta_xlarge_512_reinit: mean_weight -> 0.07966986128643644\n",
      "ghts/deberta_v3_base_512_reinit_pseudo: mean_weight -> 0.041184189963520794\n",
      "ghts/deberta_v3_large_4096_reinit_pseudo: mean_weight -> 0.05442054351642984\n",
      "ghts/deberta_xlarge_512_reinit_pseudo: mean_weight -> 0.09187152607213299\n",
      "ghts/deberta_v3_base_512_reinit_svr_pseudo: mean_weight -> 0.08818349012236444\n",
      "ghts/deberta_v3_large_4096_reinit_svr_pseudo: mean_weight -> 0.0713517514210638\n",
      "ghts/deberta_xlarge_512_reinit_svr_pseudo: mean_weight -> 0.09428305593029931\n",
      "ghts/deberta_v3_large_4096_svr: mean_weight -> 0.09237627122236201\n",
      "ghts/deberta_large_512_svr: mean_weight -> 0.05250456537893666\n",
      "ghts/deberta_v3_base_4096_svr: mean_weight -> 0.054920048089673316\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'save_weight_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cfg, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cfg_list, np\u001b[38;5;241m.\u001b[39mmean(weights_list, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_weight_folder\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m9\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: mean_weight -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'save_weight_folder'"
     ]
    }
   ],
   "source": [
    "for cfg, w in zip(cfg_list, np.mean(weights_list, axis=(0,1))):\n",
    "    print(f\"{cfg['save_weight_folder'][9:]}: mean_weight -> {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T10:26:46.557824Z",
     "iopub.status.busy": "2022-11-26T10:26:46.557669Z",
     "iopub.status.idle": "2022-11-26T10:26:46.561897Z",
     "shell.execute_reply": "2022-11-26T10:26:46.561290Z",
     "shell.execute_reply.started": "2022-11-26T10:26:46.557809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghts/deberta_v3_base_512_reinit: mean_weight -> 0.01808425191965541\n",
      "ghts/deberta_v3_base_4096_reinit: mean_weight -> 0.07036672875689522\n",
      "ghts/deberta_large_512_reinit: mean_weight -> 0.13240250115054272\n",
      "ghts/muppet_large_512_reinit: mean_weight -> 0.11607240887900794\n",
      "ghts/deberta_xlarge_512_reinit: mean_weight -> 0.1378779334227738\n",
      "ghts/deberta_v3_base_512_reinit_pseudo: mean_weight -> 0.06254180381731195\n",
      "ghts/deberta_v3_large_512_reinit_pseudo: mean_weight -> 0.11073394898863492\n",
      "ghts/deberta_v3_large_4096_reinit_pseudo: mean_weight -> 0.10644554013071185\n",
      "ghts/deberta_xlarge_512_reinit_pseudo: mean_weight -> 0.14485640234187258\n",
      "ghts/deberta_v3_base_512_reinit_svr_pseudo: mean_weight -> 0.10178945156293184\n"
     ]
    }
   ],
   "source": [
    "for cfg, w in zip(cfg_list, np.mean(weights_list, axis=(0,1))):\n",
    "    print(f\"{cfg['save_weight_folder'][9:]}: mean_weight -> {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T13:49:58.364701Z",
     "iopub.status.busy": "2022-11-25T13:49:58.364199Z",
     "iopub.status.idle": "2022-11-25T13:49:58.367726Z",
     "shell.execute_reply": "2022-11-25T13:49:58.367403Z",
     "shell.execute_reply.started": "2022-11-25T13:49:58.364674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghts/deberta_v3_base_512_reinit_pseudo: mean_weight -> 0.11638717828936428\n",
      "ghts/deberta_v3_base_4096_reinit_pseudo: mean_weight -> 0.11545940443971185\n",
      "ghts/deberta_v3_large_512_reinit_pseudo: mean_weight -> 0.12636836477094585\n",
      "ghts/deberta_v3_large_4096_reinit_pseudo: mean_weight -> 0.11533129744016073\n",
      "ghts/deberta_large_512_reinit_pseudo: mean_weight -> 0.12631688386954354\n",
      "ghts/muppet_large_512_reinit_pseudo: mean_weight -> 0.1146294283697651\n",
      "ghts/deberta_xlarge_512_reinit_pseudo: mean_weight -> 0.28604372202085193\n"
     ]
    }
   ],
   "source": [
    "for cfg, w in zip(cfg_list, np.mean(weights_list, axis=(0,1))):\n",
    "    print(f\"{cfg['save_weight_folder'][9:]}: mean_weight -> {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T08:53:09.928378Z",
     "iopub.status.busy": "2022-11-23T08:53:09.928048Z",
     "iopub.status.idle": "2022-11-23T08:53:09.933082Z",
     "shell.execute_reply": "2022-11-23T08:53:09.932293Z",
     "shell.execute_reply.started": "2022-11-23T08:53:09.928354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghts/deberta_v3_base_512_reinit: mean_weight -> 0.0851821266004092\n",
      "ghts/deberta_v3_base_4096_reinit: mean_weight -> 0.15075516345919657\n",
      "ghts/deberta_v3_large_512_reinit: mean_weight -> 0.1153585078458238\n",
      "ghts/deberta_v3_large_4096_reinit: mean_weight -> 0.09972915365392339\n",
      "ghts/deberta_large_512_reinit: mean_weight -> 0.1261354354129243\n",
      "ghts/muppet_large_512_reinit: mean_weight -> 0.18652713693522452\n",
      "ghts/deberta_xlarge_512_reinit: mean_weight -> 0.231936107009877\n"
     ]
    }
   ],
   "source": [
    "for cfg, w in zip(cfg_list, np.mean(weights_list, axis=(0,1))):\n",
    "    print(f\"{cfg['save_weight_folder'][9:]}: mean_weight -> {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blending only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:30:01.370471Z",
     "iopub.status.busy": "2022-11-29T04:30:01.370084Z",
     "iopub.status.idle": "2022-11-29T04:30:14.531564Z",
     "shell.execute_reply": "2022-11-29T04:30:14.530989Z",
     "shell.execute_reply.started": "2022-11-29T04:30:01.370440Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "\n",
      "simple_mean: mcrmse_score:0.4395834204129965, mcrmse_scores:[0.46872539000118907, 0.4483134018254309, 0.394330463024263, 0.4428740386945851, 0.4470923958632945, 0.436164833069216]\n",
      "cfg_0: mcrmse_score:0.44640483963315886, mcrmse_scores:[0.47736600030859094, 0.45743326943302653, 0.4035178557604888, 0.4472353210330416, 0.45255893482328374, 0.44031765644052184]\n",
      "cfg_1: mcrmse_score:0.44796350194232004, mcrmse_scores:[0.47839677325350755, 0.4500609600486165, 0.40672602294122245, 0.4542348897733609, 0.456231321472265, 0.4421310441649481]\n",
      "cfg_2: mcrmse_score:0.4518655966614231, mcrmse_scores:[0.47610925836151624, 0.466663764963195, 0.403818631302194, 0.45068034843863386, 0.4641070886183531, 0.44981448828464643]\n",
      "cfg_3: mcrmse_score:0.44576787552777325, mcrmse_scores:[0.47463702963341237, 0.45031524767192027, 0.398496345404305, 0.4497555901222513, 0.4560446593306536, 0.4453583810040973]\n",
      "cfg_4: mcrmse_score:0.44400730227612345, mcrmse_scores:[0.4749378623469204, 0.4534323983125786, 0.3995082979821595, 0.4459138344145677, 0.45244755950075377, 0.43780386109976094]\n",
      "cfg_5: mcrmse_score:0.44392140697254895, mcrmse_scores:[0.4721428489273832, 0.4528822484170729, 0.4005746607697104, 0.4487866420005934, 0.4496669119485282, 0.43947512977200537]\n",
      "cfg_6: mcrmse_score:0.4419459502992041, mcrmse_scores:[0.46944567439592527, 0.44815550236846435, 0.39666043195285317, 0.44328323409390624, 0.4521334834824832, 0.441997375501592]\n",
      "cfg_7: mcrmse_score:0.4499384789052617, mcrmse_scores:[0.4832301623008842, 0.46116951162349856, 0.40001081640003733, 0.45274576191715943, 0.4570479583191143, 0.4454266628708763]\n",
      "cfg_8: mcrmse_score:0.4505933852236725, mcrmse_scores:[0.48312369069547, 0.45802994725262536, 0.40278786982165704, 0.4545187638487608, 0.4592743170145983, 0.44582572270892296]\n",
      "cfg_9: mcrmse_score:0.45075812446612246, mcrmse_scores:[0.4807777676642173, 0.45522515691908055, 0.4020169725719855, 0.4524570616084957, 0.4638037632297645, 0.45026802480319095]\n",
      "cfg_10: mcrmse_score:0.44768794380412863, mcrmse_scores:[0.483815811352151, 0.45392013517515795, 0.4025646170271289, 0.4490566737607938, 0.45507680072263595, 0.44169362478690427]\n",
      "cfg_11: mcrmse_score:0.4521549494628317, mcrmse_scores:[0.4846728656918563, 0.4606417357696474, 0.3975023961560663, 0.45532644259006655, 0.4632851607942896, 0.4515010957750641]\n",
      "cfg_12: mcrmse_score:0.4483251269848661, mcrmse_scores:[0.4858544435159419, 0.45353203402148096, 0.3984135032141631, 0.45120899703110384, 0.4562922220443154, 0.44464956208219136]\n",
      "cfg_13: mcrmse_score:0.4464640741056058, mcrmse_scores:[0.47836937090551207, 0.45911133795152215, 0.40175991927578925, 0.44707565242355934, 0.4499893331182982, 0.44247883095895346]\n",
      "optimized: mcrmse_score:0.43938150040185214, mcrmse_scores:[0.46752559446239006, 0.44803579181739767, 0.39352561297333477, 0.44285913284493805, 0.4473316488873362, 0.4370112214257159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "\n",
      "simple_mean: mcrmse_score:0.4452882493930122, mcrmse_scores:[0.4739343422767327, 0.43376635437729216, 0.4078216219628406, 0.46127071379410706, 0.45972364668874494, 0.435212817258356]\n",
      "cfg_0: mcrmse_score:0.4591567243002456, mcrmse_scores:[0.49545116605691003, 0.44508254136252245, 0.42248581875415736, 0.4721200765252766, 0.470575918965479, 0.4492248241371281]\n",
      "cfg_1: mcrmse_score:0.4501004886269688, mcrmse_scores:[0.4794066833124652, 0.43651016340763094, 0.41523658292584614, 0.46139840296625045, 0.46731349803980354, 0.44073760110981597]\n",
      "cfg_2: mcrmse_score:0.4570095519387465, mcrmse_scores:[0.4806723645246442, 0.4454368570035867, 0.41548546576200046, 0.469845180271951, 0.4764595068719748, 0.454157937198322]\n",
      "cfg_3: mcrmse_score:0.4494251824734414, mcrmse_scores:[0.47927391733913083, 0.4341051645923393, 0.41139067713698285, 0.4665578025512364, 0.4657478328850537, 0.4394757003359052]\n",
      "cfg_4: mcrmse_score:0.4513923575817543, mcrmse_scores:[0.4829377182359557, 0.43899788702306225, 0.4148507045933215, 0.46724832983758924, 0.4640935207610084, 0.44022598503958893]\n",
      "cfg_5: mcrmse_score:0.4484459410245815, mcrmse_scores:[0.47805360879001935, 0.4379954072471864, 0.40948062427068627, 0.46459497398682076, 0.4618885266028861, 0.4386625052498901]\n",
      "cfg_6: mcrmse_score:0.44762133151451383, mcrmse_scores:[0.4749830822351564, 0.4359562800867287, 0.4104665069203125, 0.4639968529781211, 0.463984733227765, 0.43634053363899933]\n",
      "cfg_7: mcrmse_score:0.45541209517604747, mcrmse_scores:[0.48958263646519146, 0.4412954281739044, 0.4175636147074807, 0.4719983810762932, 0.4691267756217471, 0.44290573501166813]\n",
      "cfg_8: mcrmse_score:0.45364297501323025, mcrmse_scores:[0.48510413630379395, 0.44503879553880527, 0.4155274989187876, 0.4668495667041172, 0.4701946632070312, 0.4391431894068462]\n",
      "cfg_9: mcrmse_score:0.45636642638750763, mcrmse_scores:[0.48204235593566985, 0.4437564784195446, 0.4162366679396298, 0.47263313881416785, 0.4787646425265323, 0.44476527468950183]\n",
      "cfg_10: mcrmse_score:0.4523263627902025, mcrmse_scores:[0.4804590053980467, 0.4430358984856402, 0.41184771592026603, 0.4680189249873153, 0.4668243937099365, 0.44377223824001044]\n",
      "cfg_11: mcrmse_score:0.4539614039396884, mcrmse_scores:[0.48503605518266746, 0.44283478106982327, 0.4094293722522921, 0.47067132770380377, 0.47062019633787533, 0.4451766910916685]\n",
      "cfg_12: mcrmse_score:0.4547795363769076, mcrmse_scores:[0.4875514808442886, 0.44619592434798594, 0.4104873100000719, 0.46942343008525655, 0.4705240251481081, 0.4444950478357343]\n",
      "cfg_13: mcrmse_score:0.4561982087043377, mcrmse_scores:[0.491855117550744, 0.4432972277146879, 0.41981284744180464, 0.4707393630313468, 0.4666866355716095, 0.4447980609158333]\n",
      "optimized: mcrmse_score:0.4443667928148725, mcrmse_scores:[0.4721469890579674, 0.4329866733704151, 0.40652339281900746, 0.4604867441349401, 0.45958126843554686, 0.434475689071358]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.44897154114473464, mcrmse_scores:[0.4833268370763778, 0.4528480897197775, 0.4090392770053821, 0.4340088423627159, 0.46491287880428556, 0.4496933218998687]\n",
      "cfg_0: mcrmse_score:0.45598181902917706, mcrmse_scores:[0.49275559121976914, 0.45920548350873497, 0.41902340673734306, 0.4404931566534003, 0.46747934262175905, 0.4569339334340556]\n",
      "cfg_1: mcrmse_score:0.4607981980510454, mcrmse_scores:[0.49793969719573805, 0.4656664558472726, 0.4198178404521915, 0.44341782916535966, 0.4761875320384251, 0.461759833607285]\n",
      "cfg_2: mcrmse_score:0.46586662530580303, mcrmse_scores:[0.5048782083583988, 0.46431786827989324, 0.4281608256036924, 0.45237744861036566, 0.48481347881348524, 0.4606519221689827]\n",
      "cfg_3: mcrmse_score:0.4526238439788073, mcrmse_scores:[0.48634174180172873, 0.4580202636777276, 0.41096537377691544, 0.437138527853342, 0.4689966441645442, 0.4542805125985855]\n",
      "cfg_4: mcrmse_score:0.4540362309041926, mcrmse_scores:[0.48805045893386967, 0.4570092297762306, 0.4175634038858818, 0.43677881905709975, 0.46937812063948753, 0.45543735313258615]\n",
      "cfg_5: mcrmse_score:0.45212575049040243, mcrmse_scores:[0.48789419903855064, 0.45479066606714724, 0.4128193391795571, 0.436223749765252, 0.4670813533060304, 0.45394519558587726]\n",
      "cfg_6: mcrmse_score:0.4508383858434246, mcrmse_scores:[0.48604685099338796, 0.45688582185527854, 0.40741067862627744, 0.4363123729413935, 0.46689838671547657, 0.45147620392873333]\n",
      "cfg_7: mcrmse_score:0.457766845528432, mcrmse_scores:[0.48996483316131584, 0.45844819888073535, 0.4163832756789711, 0.4505268949962704, 0.4738292144603142, 0.4574486559929851]\n",
      "cfg_8: mcrmse_score:0.459711196621277, mcrmse_scores:[0.49474073933742185, 0.46394110479405626, 0.41184883907581826, 0.4486655718791663, 0.4809069369352002, 0.45816398770599887]\n",
      "cfg_9: mcrmse_score:0.45802752747901704, mcrmse_scores:[0.49731813917326023, 0.4631730125409969, 0.41403432336704105, 0.4449830102982087, 0.4727264062412667, 0.4559302732533286]\n",
      "cfg_10: mcrmse_score:0.45607528766244165, mcrmse_scores:[0.4952806327648468, 0.4576899734085342, 0.4125954464292958, 0.43941559476867253, 0.4742363908284833, 0.4572336877748173]\n",
      "cfg_11: mcrmse_score:0.4593321957360091, mcrmse_scores:[0.4963357170748607, 0.464884535273588, 0.4165907125753918, 0.44088695007078776, 0.4765440266445968, 0.4607512327768294]\n",
      "cfg_12: mcrmse_score:0.4618683357799833, mcrmse_scores:[0.5028906959607108, 0.4630045735007018, 0.4164166442054479, 0.4424030131445639, 0.4798333030609083, 0.46666178480756776]\n",
      "cfg_13: mcrmse_score:0.45843066960849255, mcrmse_scores:[0.4905329872646948, 0.46073863319842584, 0.4236947999435484, 0.4420706186409205, 0.4729181669608831, 0.46062881164248237]\n",
      "optimized: mcrmse_score:0.44862425316992405, mcrmse_scores:[0.48310679839805704, 0.45267950503514454, 0.408000354410572, 0.434366370593789, 0.46445831539607374, 0.44913417518590776]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.44530525169450685, mcrmse_scores:[0.4664746843174213, 0.4322829172672516, 0.4141041594223839, 0.4496427099156052, 0.4809143321419051, 0.4284127071024743]\n",
      "cfg_0: mcrmse_score:0.4546369433395701, mcrmse_scores:[0.4786551465687863, 0.44320550067310543, 0.42163403904173097, 0.4534669652670811, 0.4865551089312972, 0.4443048995554197]\n",
      "cfg_1: mcrmse_score:0.45042563007718556, mcrmse_scores:[0.4660897480364336, 0.4373463190649996, 0.41801434849792535, 0.4545812768035626, 0.4903899016611934, 0.4361321863989987]\n",
      "cfg_2: mcrmse_score:0.45579571088171417, mcrmse_scores:[0.47435089142660203, 0.44522336659534023, 0.42129983954035355, 0.46141449307764115, 0.49318820793316054, 0.4392974667171875]\n",
      "cfg_3: mcrmse_score:0.45217216145887673, mcrmse_scores:[0.47916371639949384, 0.438520755551073, 0.4164349596284445, 0.4600609179768817, 0.4876288898203114, 0.43122372937705616]\n",
      "cfg_4: mcrmse_score:0.4494843434855242, mcrmse_scores:[0.4748800706978306, 0.43535515606088465, 0.417091522623616, 0.4494455261610361, 0.4870635451805069, 0.4330702401892704]\n",
      "cfg_5: mcrmse_score:0.4491996685075883, mcrmse_scores:[0.47308664890496493, 0.4392901316639987, 0.4184433790141843, 0.45098352998371455, 0.4817978346197237, 0.43159648685894375]\n",
      "cfg_6: mcrmse_score:0.4484264072321977, mcrmse_scores:[0.47025736459751416, 0.4333543468293386, 0.41595432863086806, 0.4548926924333342, 0.4872833444055645, 0.4288163664965662]\n",
      "cfg_7: mcrmse_score:0.4528641391697404, mcrmse_scores:[0.47482037158545704, 0.4357546506254134, 0.4202424221955821, 0.4538836338553317, 0.4932929412598689, 0.4391908154967891]\n",
      "cfg_8: mcrmse_score:0.4506021574297823, mcrmse_scores:[0.46962583027881966, 0.43858841767768375, 0.42120077133048534, 0.4536497490987997, 0.48567941909842804, 0.4348687570944778]\n",
      "cfg_9: mcrmse_score:0.45247780573228336, mcrmse_scores:[0.47039646400094526, 0.43478393492270345, 0.42080619211322323, 0.4621164620553779, 0.49470069749412293, 0.43206308380732744]\n",
      "cfg_10: mcrmse_score:0.4537649439464382, mcrmse_scores:[0.48014852888361004, 0.4384486382342658, 0.4231174895917592, 0.45802568578381686, 0.48472795062832696, 0.43812137055684985]\n",
      "cfg_11: mcrmse_score:0.45749360448316545, mcrmse_scores:[0.48362869336215464, 0.4475152829967566, 0.4205478651921329, 0.4635892590709778, 0.4938478866539192, 0.4358326396230514]\n",
      "cfg_12: mcrmse_score:0.4530520747822933, mcrmse_scores:[0.4765937209815579, 0.44056194513709307, 0.4219944291594359, 0.4588581292788522, 0.48410745234413755, 0.4361967717926832]\n",
      "cfg_13: mcrmse_score:0.45532558455675304, mcrmse_scores:[0.47869083112250216, 0.440257304576528, 0.4251748264338545, 0.45288159374341547, 0.4909443414396429, 0.4440046100245754]\n",
      "optimized: mcrmse_score:0.444449214617516, mcrmse_scores:[0.4643173135179787, 0.4308978886430979, 0.41384833992955183, 0.44920587840620785, 0.4804236623831935, 0.4280022048250661]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.4418603842045263, mcrmse_scores:[0.4650295479620753, 0.4221627827221631, 0.4122575878243325, 0.4502636911368272, 0.462159029038597, 0.43928966654316226]\n",
      "cfg_0: mcrmse_score:0.4517432058281796, mcrmse_scores:[0.47790252081984874, 0.42759786637027475, 0.4232340058467752, 0.4588235932990546, 0.47044895824130306, 0.45245229039182144]\n",
      "cfg_1: mcrmse_score:0.4474640998250639, mcrmse_scores:[0.47378012786355067, 0.42520154386126247, 0.41987411796431484, 0.4547621280443761, 0.4684081530656485, 0.44275852815123135]\n",
      "cfg_2: mcrmse_score:0.45474245588007145, mcrmse_scores:[0.47896108741292504, 0.4353564752441213, 0.419943114849705, 0.46247888795965925, 0.47652757759760483, 0.4551875922164135]\n",
      "cfg_3: mcrmse_score:0.4509786768557819, mcrmse_scores:[0.4730383834428002, 0.43105428880088453, 0.420076257551725, 0.45826358489383207, 0.47439672919999937, 0.44904281724545003]\n",
      "cfg_4: mcrmse_score:0.4456061886395044, mcrmse_scores:[0.47043601950456565, 0.4247738142780557, 0.41727188594703873, 0.45439039982591134, 0.4648526529903222, 0.4419123592911326]\n",
      "cfg_5: mcrmse_score:0.44620144447381155, mcrmse_scores:[0.4698193252581817, 0.42705557777811237, 0.4181404899501098, 0.4510418720818392, 0.46947826224806927, 0.4416731395265565]\n",
      "cfg_6: mcrmse_score:0.44691575269568035, mcrmse_scores:[0.4699666983768682, 0.42729950225540597, 0.4157008738459265, 0.45395279309038594, 0.47199928788004003, 0.4425753607254553]\n",
      "cfg_7: mcrmse_score:0.4484701966852856, mcrmse_scores:[0.4802683470475302, 0.42515595505645987, 0.42013375081130566, 0.45779605292499714, 0.4633409047551504, 0.44412616951627076]\n",
      "cfg_8: mcrmse_score:0.45110633947676004, mcrmse_scores:[0.4732825455309148, 0.4332424346578869, 0.4230107182419888, 0.45720935161827336, 0.4729457470342629, 0.4469472397772333]\n",
      "cfg_9: mcrmse_score:0.4513519586781976, mcrmse_scores:[0.47928169947921967, 0.43032278735371293, 0.4168310035407983, 0.46058171125738556, 0.4716657762526188, 0.4494287741854506]\n",
      "cfg_10: mcrmse_score:0.44983047504576473, mcrmse_scores:[0.47830534113223944, 0.43520063255908836, 0.4173369624250953, 0.45482813481806617, 0.46812010582163993, 0.4451916735184597]\n",
      "cfg_11: mcrmse_score:0.45355228487521243, mcrmse_scores:[0.4753213219942976, 0.43419730323643185, 0.4182405968198867, 0.463000102485932, 0.4769070356517753, 0.45364734906295123]\n",
      "cfg_12: mcrmse_score:0.45285619623094414, mcrmse_scores:[0.476267202138535, 0.4372230428527562, 0.41884593345454235, 0.46088482147933335, 0.4701093959054172, 0.453806781555081]\n",
      "cfg_13: mcrmse_score:0.45007391324654417, mcrmse_scores:[0.47656555477175067, 0.42668621938517953, 0.4234716260023194, 0.4582788618370694, 0.467043696258952, 0.44839752122399396]\n",
      "optimized: mcrmse_score:0.4413217515616495, mcrmse_scores:[0.465113512679781, 0.42130489691749234, 0.4114375976508043, 0.4497518300683292, 0.4614104057620507, 0.43891226629143987]\n",
      "simple mean_cv score:0.44420176936995526\n",
      "simple mean_cv score:[0.47149816 0.43787471 0.40751062 0.447612   0.46296046 0.43775467]\n",
      "optimized mean_cv score:0.44362870251316283\n",
      "optimized mean_cv score:[0.47044204 0.43718095 0.40666706 0.44733399 0.46264106 0.43750711]\n",
      "fold0: score_cv[i]\n",
      "fold1: score_cv[i]\n",
      "fold2: score_cv[i]\n",
      "fold3: score_cv[i]\n",
      "fold4: score_cv[i]\n"
     ]
    }
   ],
   "source": [
    "preds_list_valid_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "score_cv = []\n",
    "scores_cv = []\n",
    "simple_score_cv = []\n",
    "simple_scores_cv = []\n",
    "for j, fold_n in enumerate(fold_list):\n",
    "    preds_list = []\n",
    "    _, valid_indices = list(skf.split(train_X, train_y))[fold_n]\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        valid_preds = one_fold_valid(skf, cfg, valid_X_cv, valid_y_cv, fold_n)\n",
    "        preds_list.append(valid_preds)\n",
    "        del valid_preds\n",
    "        gc.collect()\n",
    "\n",
    "    score, scores = mcrmse(valid_y_cv.values, np.mean(preds_list, axis=0))\n",
    "    print()\n",
    "    print(f\"simple_mean: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    simple_score_cv.append(score)\n",
    "    simple_scores_cv.append(scores)\n",
    "    for i, p in enumerate(preds_list):\n",
    "        score, scores = mcrmse(valid_y_cv.values, p)\n",
    "        print(f\"cfg_{i}: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    preds_list = np.array(preds_list)\n",
    "    \n",
    "    # blending\n",
    "    preds_list_valid_cv[j] = np.zeros(preds_list[0].shape)\n",
    "    for i in range(preds_list.shape[0]):\n",
    "        preds_list_valid_cv[j][:, 0] += preds_list[i, :, 0] * avg_weights_cohesion[i]\n",
    "        preds_list_valid_cv[j][:, 1] += preds_list[i, :, 1] * avg_weights_syntax[i]\n",
    "        preds_list_valid_cv[j][:, 2] += preds_list[i, :, 2] * avg_weights_vocabulary[i]\n",
    "        preds_list_valid_cv[j][:, 3] += preds_list[i, :, 3] * avg_weights_phraseology[i]\n",
    "        preds_list_valid_cv[j][:, 4] += preds_list[i, :, 4] * avg_weights_grammar[i]\n",
    "        preds_list_valid_cv[j][:, 5] += preds_list[i, :, 5] * avg_weights_conventions[i]\n",
    "        \n",
    "    score, scores = mcrmse(valid_y_cv.values, preds_list_valid_cv[j])\n",
    "    print(f\"optimized: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    score_cv.append(score)\n",
    "    scores_cv.append(scores)\n",
    "\n",
    "print(f\"simple mean_cv score:{np.mean(simple_score_cv)}\")\n",
    "print(f\"simple mean_cv score:{np.mean(simple_scores_cv, axis=0)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")\n",
    "for i in range(len(score_cv)):\n",
    "    print(f\"fold{i}: score_cv[i]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:30:17.160761Z",
     "iopub.status.busy": "2022-11-29T04:30:17.160137Z",
     "iopub.status.idle": "2022-11-29T04:30:17.165316Z",
     "shell.execute_reply": "2022-11-29T04:30:17.164747Z",
     "shell.execute_reply.started": "2022-11-29T04:30:17.160734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.44362870251316283\n",
      "optimized mean_cv score:[0.47044204 0.43718095 0.40666706 0.44733399 0.46264106 0.43750711]\n",
      "fold0: 0.43938150040185214\n",
      "fold1: 0.4443667928148725\n",
      "fold2: 0.44862425316992405\n",
      "fold3: 0.444449214617516\n",
      "fold4: 0.4413217515616495\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")\n",
    "for i in range(len(score_cv)):\n",
    "    print(f\"fold{i}: {score_cv[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T07:36:58.688274Z",
     "iopub.status.busy": "2022-11-27T07:36:58.688079Z",
     "iopub.status.idle": "2022-11-27T07:36:58.692673Z",
     "shell.execute_reply": "2022-11-27T07:36:58.692075Z",
     "shell.execute_reply.started": "2022-11-27T07:36:58.688256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.4442963443345695\n",
      "optimized mean_cv score:[0.47144265 0.43754408 0.40820216 0.44737376 0.46324763 0.43796779]\n",
      "fold0: 0.43962936055108504\n",
      "fold1: 0.4446806390236411\n",
      "fold2: 0.4495163950172176\n",
      "fold3: 0.44551959500246796\n",
      "fold4: 0.4421357320784356\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")\n",
    "for i in range(len(score_cv)):\n",
    "    print(f\"fold{i}: {score_cv[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T07:35:02.811080Z",
     "iopub.status.busy": "2022-11-27T07:35:02.810848Z",
     "iopub.status.idle": "2022-11-27T07:35:02.815443Z",
     "shell.execute_reply": "2022-11-27T07:35:02.814786Z",
     "shell.execute_reply.started": "2022-11-27T07:35:02.811060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.4439758496123359\n",
      "optimized mean_cv score:[0.47048388 0.43723195 0.40779752 0.44744441 0.46317166 0.43772568]\n",
      "fold0: 0.43966736498166054\n",
      "fold1: 0.4447260160321184\n",
      "fold2: 0.4490585447406838\n",
      "fold3: 0.44465007540737683\n",
      "fold4: 0.44177724689983977\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")\n",
    "for i in range(len(score_cv)):\n",
    "    print(f\"fold{i}: {score_cv[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T07:33:41.783000Z",
     "iopub.status.busy": "2022-11-27T07:33:41.782700Z",
     "iopub.status.idle": "2022-11-27T07:33:41.793796Z",
     "shell.execute_reply": "2022-11-27T07:33:41.789958Z",
     "shell.execute_reply.started": "2022-11-27T07:33:41.782978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.4435757923511847\n",
      "optimized mean_cv score:[0.47044186 0.43698109 0.40659112 0.44745059 0.4626017  0.43738839]\n",
      "fold0: 0.4392709463063429\n",
      "fold1: 0.44423089670219973\n",
      "fold2: 0.44890168720608276\n",
      "fold3: 0.4442636474010416\n",
      "fold4: 0.4412117841402565\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")\n",
    "for i in range(len(score_cv)):\n",
    "    print(f\"fold{i}: {score_cv[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T19:55:17.489759Z",
     "iopub.status.busy": "2022-11-26T19:55:17.488988Z",
     "iopub.status.idle": "2022-11-26T19:55:17.494291Z",
     "shell.execute_reply": "2022-11-26T19:55:17.493578Z",
     "shell.execute_reply.started": "2022-11-26T19:55:17.489729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.44402996448356824\n",
      "optimized mean_cv score:[0.47047417 0.43735069 0.40790291 0.44751299 0.46322585 0.43771317]\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:57:37.907343Z",
     "iopub.status.busy": "2022-11-26T09:57:37.906968Z",
     "iopub.status.idle": "2022-11-26T09:57:37.913188Z",
     "shell.execute_reply": "2022-11-26T09:57:37.912721Z",
     "shell.execute_reply.started": "2022-11-26T09:57:37.907321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.444213507082441\n",
      "optimized mean_cv score:[0.47145325 0.43764378 0.40772634 0.44727526 0.463229   0.4379534 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:59:43.224967Z",
     "iopub.status.busy": "2022-11-26T09:59:43.224578Z",
     "iopub.status.idle": "2022-11-26T09:59:43.228324Z",
     "shell.execute_reply": "2022-11-26T09:59:43.227901Z",
     "shell.execute_reply.started": "2022-11-26T09:59:43.224948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.4442963443345695\n",
      "optimized mean_cv score:[0.47144265 0.43754408 0.40820216 0.44737376 0.46324763 0.43796779]\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T14:08:50.869826Z",
     "iopub.status.busy": "2022-11-25T14:08:50.869646Z",
     "iopub.status.idle": "2022-11-25T14:08:50.872889Z",
     "shell.execute_reply": "2022-11-25T14:08:50.872459Z",
     "shell.execute_reply.started": "2022-11-25T14:08:50.869811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean_cv score:0.4444073891630994\n",
      "optimized mean_cv score:[0.4716746  0.43770278 0.40836213 0.44728157 0.46330418 0.43811907]\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize blending only (ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T03:44:57.162003Z",
     "iopub.status.busy": "2022-11-26T03:44:57.160910Z",
     "iopub.status.idle": "2022-11-26T03:44:57.166348Z",
     "shell.execute_reply": "2022-11-26T03:44:57.165788Z",
     "shell.execute_reply.started": "2022-11-26T03:44:57.161949Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_fold_train_valid(skf, cfg, train_X, valid_X, valid_y, fold_n):\n",
    "    print(f\"[fold_{fold_n}]\")\n",
    "    seed_everything(cfg[\"general\"][\"seed\"], workers=True)\n",
    "\n",
    "    if use_computed:\n",
    "        valid_preds = joblib.load(f\"../data/preds/valid_{cfg['general']['seed']}_{cfg['general']['save_name']}_{fold_n}.preds\")\n",
    "        train_preds = joblib.load(f\"../data/preds/train_{cfg['general']['seed']}_{cfg['general']['save_name']}_{fold_n}.preds\")\n",
    "    else:\n",
    "        model = TransformersRegressorInference(cfg, f\"{cfg['save_weight_folder']}/last_epoch_fold{fold_n}.ckpt\")\n",
    "        train_preds = model.predict(train_X)\n",
    "        valid_preds = model.predict(valid_X)\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    score, scores = mcrmse(valid_y.values, valid_preds)\n",
    "    #print(f\"mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    return train_preds, valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T03:47:19.383241Z",
     "iopub.status.busy": "2022-11-26T03:47:19.382456Z",
     "iopub.status.idle": "2022-11-26T03:47:21.735834Z",
     "shell.execute_reply": "2022-11-26T03:47:21.734990Z",
     "shell.execute_reply.started": "2022-11-26T03:47:19.383205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.4426928168821353, mcrmse_scores:[0.4723965305254995, 0.4514796506367955, 0.39961054506159743, 0.4468851391595757, 0.45096718197024305, 0.4348178539391007]\n",
      "cfg_0: mcrmse_score:0.44501512108121055, mcrmse_scores:[0.4764805445068816, 0.4555338394273924, 0.4005444619125103, 0.44667452673163766, 0.45393005510740025, 0.43692729880144127]\n",
      "cfg_1: mcrmse_score:0.44585454507407873, mcrmse_scores:[0.4752488045513762, 0.4521792429120024, 0.40275357229592157, 0.4525966114288518, 0.45402999895842294, 0.4383190402978972]\n",
      "mcrmse_score:0.6487136152041301\n",
      "mcrmse_score:0.6364518325892338\n",
      "mcrmse_score:0.5732140998715254\n",
      "mcrmse_score:0.645201856731233\n",
      "mcrmse_score:0.6846099611419565\n",
      "mcrmse_score:0.6755270957628826\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "\n",
      "simple_mean: mcrmse_score:0.44893859810151504, mcrmse_scores:[0.48015190225881454, 0.43539356533108375, 0.4131365927689932, 0.46273905657694336, 0.4634437967369345, 0.43876667493632093]\n",
      "cfg_0: mcrmse_score:0.4540036310035572, mcrmse_scores:[0.4870439937420945, 0.4405176574789289, 0.4180377667606487, 0.4691943038286734, 0.4652141963197483, 0.4440138678912489]\n",
      "cfg_1: mcrmse_score:0.4497267532055142, mcrmse_scores:[0.47982201385823264, 0.4361583982330732, 0.412478175838036, 0.46235779538511373, 0.46780953246751567, 0.4397346034511142]\n",
      "mcrmse_score:0.6553043780551817\n",
      "mcrmse_score:0.6450153060479489\n",
      "mcrmse_score:0.5685493636787861\n",
      "mcrmse_score:0.6593212640777231\n",
      "mcrmse_score:0.6849967725111159\n",
      "mcrmse_score:0.6705775717304987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n",
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.4514441601928491, mcrmse_scores:[0.4856637628169569, 0.4554032936501573, 0.41298292435028466, 0.43593396101140786, 0.46717078404460605, 0.4515102352836817]\n",
      "cfg_0: mcrmse_score:0.4531859084788503, mcrmse_scores:[0.490160092871873, 0.4573422915189093, 0.4155366559001389, 0.43755778526982453, 0.46615787786846385, 0.4523607474438923]\n",
      "cfg_1: mcrmse_score:0.4554363794631861, mcrmse_scores:[0.4878428596412498, 0.4583787537232134, 0.41515343018894074, 0.4400479646255586, 0.4748851030804708, 0.45631016551968295]\n",
      "mcrmse_score:0.6806161716122952\n",
      "mcrmse_score:0.6521264839369915\n",
      "mcrmse_score:0.583164419383919\n",
      "mcrmse_score:0.6394748426348342\n",
      "mcrmse_score:0.7013045569015239\n",
      "mcrmse_score:0.6835986266733428\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.4469928527020628, mcrmse_scores:[0.46862523782535, 0.4345103312348706, 0.4147866410704356, 0.44777399182239497, 0.4850766082227587, 0.43118430603656693]\n",
      "cfg_0: mcrmse_score:0.4506304738031212, mcrmse_scores:[0.4747445894753775, 0.4394010368201213, 0.4167011940470564, 0.4509580945825779, 0.48596721450075964, 0.4360107133928339]\n",
      "cfg_1: mcrmse_score:0.4486714258970248, mcrmse_scores:[0.468638873874748, 0.43482953921371054, 0.41666864833124034, 0.449739106921979, 0.4900074273148525, 0.43214495972561845]\n",
      "mcrmse_score:0.6712343221487528\n",
      "mcrmse_score:0.6403512485644408\n",
      "mcrmse_score:0.6015497522944143\n",
      "mcrmse_score:0.6622294411559594\n",
      "mcrmse_score:0.7137995398199728\n",
      "mcrmse_score:0.6586587521469858\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n",
      "\n",
      "simple_mean: mcrmse_score:0.44403544140215906, mcrmse_scores:[0.46905100019013596, 0.42279077971961193, 0.41437917001723124, 0.4513870990230649, 0.46560198363384536, 0.4410026158290654]\n",
      "cfg_0: mcrmse_score:0.4479013443036936, mcrmse_scores:[0.4718749347060132, 0.4276361751180047, 0.41820788229303213, 0.4569683701660854, 0.46699552890261825, 0.44572517463640804]\n",
      "cfg_1: mcrmse_score:0.44604118662149134, mcrmse_scores:[0.47309903345380455, 0.4241423030465027, 0.41476055688393076, 0.45127996892811634, 0.4706398927727104, 0.44232536464388345]\n",
      "mcrmse_score:0.6575495997571503\n",
      "mcrmse_score:0.6501007785695101\n",
      "mcrmse_score:0.5891370899821976\n",
      "mcrmse_score:0.6743956297334848\n",
      "mcrmse_score:0.7169897558835701\n",
      "mcrmse_score:0.6697963082165664\n"
     ]
    }
   ],
   "source": [
    "fold_list = range(cfg1[\"general\"][\"n_splits\"])\n",
    "ridge_list = [[] for _ in range(6)]\n",
    "skf = MultilabelStratifiedKFold(\n",
    "    n_splits=cfg1[\"general\"][\"n_splits\"], shuffle=True, random_state=cfg1[\"general\"][\"seed\"]\n",
    ")\n",
    "for j, fold_n in enumerate(fold_list):\n",
    "    preds_list_train = []\n",
    "    preds_list_valid = []\n",
    "    train_indices, valid_indices = list(skf.split(train_X, train_y))[fold_n]\n",
    "    train_X_cv, train_y_cv = (\n",
    "        train_X.iloc[train_indices].reset_index(drop=True),\n",
    "        train_y.iloc[train_indices].reset_index(drop=True),\n",
    "    )\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        train_preds, valid_preds = one_fold_train_valid(skf, cfg, train_X_cv, valid_X_cv, valid_y_cv, fold_n)\n",
    "        preds_list_train.append(train_preds)\n",
    "        preds_list_valid.append(valid_preds)\n",
    "        del valid_preds, train_preds\n",
    "        gc.collect()\n",
    "\n",
    "    score, scores = mcrmse(valid_y_cv.values, np.mean(preds_list_valid, axis=0))\n",
    "    print()\n",
    "    print(f\"simple_mean: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    for i, p in enumerate(preds_list_valid):\n",
    "        score, scores = mcrmse(valid_y_cv.values, p)\n",
    "        print(f\"cfg_{i}: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    preds_list_train = np.array(preds_list_train)\n",
    "    cohesion_train = preds_list_train[:, :, 0]\n",
    "    syntax_train = preds_list_train[:, :, 1]\n",
    "    vocabulary_train = preds_list_train[:, :, 2]\n",
    "    phraseology_train = preds_list_train[:, :, 3]\n",
    "    grammar_train = preds_list_train[:, :, 4]\n",
    "    conventions_train = preds_list_train[:, :, 5]\n",
    "    target_list_train = [cohesion_train, syntax_train, vocabulary_train, phraseology_train, grammar_train, conventions_train]\n",
    "\n",
    "    preds_list_valid = np.array(preds_list_valid)\n",
    "    cohesion_valid = preds_list_valid[:, :, 0]\n",
    "    syntax_valid = preds_list_valid[:, :, 1]\n",
    "    vocabulary_valid = preds_list_valid[:, :, 2]\n",
    "    phraseology_valid = preds_list_valid[:, :, 3]\n",
    "    grammar_valid = preds_list_valid[:, :, 4]\n",
    "    conventions_valid = preds_list_valid[:, :, 5]\n",
    "    target_list_valid = [cohesion_valid, syntax_valid, vocabulary_valid, phraseology_valid, grammar_valid, conventions_valid]\n",
    "    \n",
    "    for j, (target_train, target_valid) in enumerate(zip(target_list_train, target_list_valid)):\n",
    "        #clf = linear_model.BayesianRidge()\n",
    "        clf = linear_model.Lasso()\n",
    "        clf.fit(target_train.T, train_y_cv.iloc[:, j])\n",
    "        ridge_preds = clf.predict(target_valid.T)\n",
    "        score = metrics.mean_squared_error(\n",
    "            valid_y_cv.values[:, j], ridge_preds, squared=False\n",
    "        )\n",
    "        print(f\"mcrmse_score:{score}\")\n",
    "        ridge_list.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize and blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T04:29:46.181351Z",
     "iopub.status.busy": "2022-11-29T04:29:46.180797Z",
     "iopub.status.idle": "2022-11-29T04:29:53.913994Z",
     "shell.execute_reply": "2022-11-29T04:29:53.913278Z",
     "shell.execute_reply.started": "2022-11-29T04:29:46.181327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n",
      "[fold_0]\n",
      "\n",
      "simple_mean: mcrmse_score:0.4395834204129965, mcrmse_scores:[0.46872539000118907, 0.4483134018254309, 0.394330463024263, 0.4428740386945851, 0.4470923958632945, 0.436164833069216]\n",
      "cfg_0: mcrmse_score:0.44640483963315886, mcrmse_scores:[0.47736600030859094, 0.45743326943302653, 0.4035178557604888, 0.4472353210330416, 0.45255893482328374, 0.44031765644052184]\n",
      "cfg_1: mcrmse_score:0.44796350194232004, mcrmse_scores:[0.47839677325350755, 0.4500609600486165, 0.40672602294122245, 0.4542348897733609, 0.456231321472265, 0.4421310441649481]\n",
      "cfg_2: mcrmse_score:0.4518655966614231, mcrmse_scores:[0.47610925836151624, 0.466663764963195, 0.403818631302194, 0.45068034843863386, 0.4641070886183531, 0.44981448828464643]\n",
      "cfg_3: mcrmse_score:0.44576787552777325, mcrmse_scores:[0.47463702963341237, 0.45031524767192027, 0.398496345404305, 0.4497555901222513, 0.4560446593306536, 0.4453583810040973]\n",
      "cfg_4: mcrmse_score:0.44400730227612345, mcrmse_scores:[0.4749378623469204, 0.4534323983125786, 0.3995082979821595, 0.4459138344145677, 0.45244755950075377, 0.43780386109976094]\n",
      "cfg_5: mcrmse_score:0.44392140697254895, mcrmse_scores:[0.4721428489273832, 0.4528822484170729, 0.4005746607697104, 0.4487866420005934, 0.4496669119485282, 0.43947512977200537]\n",
      "cfg_6: mcrmse_score:0.4419459502992041, mcrmse_scores:[0.46944567439592527, 0.44815550236846435, 0.39666043195285317, 0.44328323409390624, 0.4521334834824832, 0.441997375501592]\n",
      "cfg_7: mcrmse_score:0.4499384789052617, mcrmse_scores:[0.4832301623008842, 0.46116951162349856, 0.40001081640003733, 0.45274576191715943, 0.4570479583191143, 0.4454266628708763]\n",
      "cfg_8: mcrmse_score:0.4505933852236725, mcrmse_scores:[0.48312369069547, 0.45802994725262536, 0.40278786982165704, 0.4545187638487608, 0.4592743170145983, 0.44582572270892296]\n",
      "cfg_9: mcrmse_score:0.45075812446612246, mcrmse_scores:[0.4807777676642173, 0.45522515691908055, 0.4020169725719855, 0.4524570616084957, 0.4638037632297645, 0.45026802480319095]\n",
      "cfg_10: mcrmse_score:0.44768794380412863, mcrmse_scores:[0.483815811352151, 0.45392013517515795, 0.4025646170271289, 0.4490566737607938, 0.45507680072263595, 0.44169362478690427]\n",
      "cfg_11: mcrmse_score:0.4521549494628317, mcrmse_scores:[0.4846728656918563, 0.4606417357696474, 0.3975023961560663, 0.45532644259006655, 0.4632851607942896, 0.4515010957750641]\n",
      "cfg_12: mcrmse_score:0.4483251269848661, mcrmse_scores:[0.4858544435159419, 0.45353203402148096, 0.3984135032141631, 0.45120899703110384, 0.4562922220443154, 0.44464956208219136]\n",
      "cfg_13: mcrmse_score:0.4464640741056058, mcrmse_scores:[0.47836937090551207, 0.45911133795152215, 0.40175991927578925, 0.44707565242355934, 0.4499893331182982, 0.44247883095895346]\n",
      "optimized_corr:0.4658483192462376\n",
      "weights:[0.020794377644139397, 1.4540148086430872e-06, 0.22229675561624507, 0.0839062763723684, 0.018079382720561855, 0.04387889294745319, 0.24448269417629448, 0.1728300542024067, 0.01905049721588182, 0.04158557161093663, 0.09943720095552375, 0.004196612881353971, 0.018146145029049425, 8.547570479911941e-05]\n",
      "optimized_corr:0.4448217473760699\n",
      "weights:[0.0008033460835426035, 0.17876702211953555, 0.00020621620789845453, 0.10839078094835611, 0.01765607095311494, 0.0357620355906627, 0.1962294835169237, 0.02781302102767725, 1.939983540602651e-05, 0.20473303251884536, 0.005735223870963101, 1.0918359430096356e-05, 0.21346295206271768, 2.025933588686765e-05]\n",
      "optimized_corr:0.39301809004941435\n",
      "weights:[0.11873254062861549, 0.0007806533232435266, 0.08086629085198604, 0.013001917855695478, 0.0006560466208182063, 0.08719757599216127, 0.1707527009411306, 0.08616987206867666, 0.0, 0.08559255830135698, 0.027395413506408076, 0.16418153386395135, 0.16447420726380613, 0.002581286062394963]\n",
      "optimized_corr:0.4403498304066884\n",
      "weights:[0.16342813983914511, 0.0009120594833139566, 0.24243165124031207, 0.24845414255274634, 0.004986136987418998, 0.00019354194386438073, 0.08864586703420267, 0.08843134342593112, 0.02986565266598037, 0.02210485670334162, 0.025032899577640606, 0.00032407683055994815, 0.07321183077868898, 0.0012837321434504179]\n",
      "optimized_corr:0.4445283003661162\n",
      "weights:[0.10624438595037848, 0.10458341748890787, 0.10907317197314598, 8.846347142147073e-05, 1.2798234418995454e-05, 0.03845847968791441, 0.15082138546437066, 0.14449287225450047, 0.011329623664407453, 0.0006212415877345306, 0.12342757852863315, 0.0063998313611998234, 0.08560002484879982, 0.10622572013686056]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_corr:0.43486146708691004\n",
      "weights:[0.16943879019953695, 0.13374667256725653, 0.060166471923693884, 0.05900960857628819, 0.12103765465657723, 0.12145929672266456, 0.04568238298165066, 0.0034841521836587895, 0.006808762724582817, 1.8408533833407225e-05, 0.11360649087507294, 0.00010132056618423452, 0.047515920926041136, 0.11481333233747368]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n",
      "[fold_1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     preds_list\u001b[38;5;241m.\u001b[39mappend(valid_preds)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m valid_preds\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m score, scores \u001b[38;5;241m=\u001b[39m mcrmse(valid_y_cv\u001b[38;5;241m.\u001b[39mvalues, np\u001b[38;5;241m.\u001b[39mmean(preds_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold_list = range(cfg1[\"general\"][\"n_splits\"])\n",
    "preds_list_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "weights_list = [[] for _ in range(6)]\n",
    "skf = MultilabelStratifiedKFold(\n",
    "    n_splits=cfg1[\"general\"][\"n_splits\"], shuffle=True, random_state=cfg1[\"general\"][\"seed\"]\n",
    ")\n",
    "for j, fold_n in enumerate(fold_list):\n",
    "    preds_list = []\n",
    "    _, valid_indices = list(skf.split(train_X, train_y))[fold_n]\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        valid_preds = one_fold_valid(skf, cfg, valid_X_cv, valid_y_cv, fold_n)\n",
    "        preds_list.append(valid_preds)\n",
    "        del valid_preds\n",
    "        gc.collect()\n",
    "\n",
    "    score, scores = mcrmse(valid_y_cv.values, np.mean(preds_list, axis=0))\n",
    "    print()\n",
    "    print(f\"simple_mean: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    for i, p in enumerate(preds_list):\n",
    "        score, scores = mcrmse(valid_y_cv.values, p)\n",
    "        print(f\"cfg_{i}: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    preds_list = np.array(preds_list)\n",
    "    preds_list_cv[j] = preds_list\n",
    "    cohesion = preds_list[:, :, 0]\n",
    "    syntax = preds_list[:, :, 1]\n",
    "    vocabulary = preds_list[:, :, 2]\n",
    "    phraseology = preds_list[:, :, 3]\n",
    "    grammar = preds_list[:, :, 4]\n",
    "    conventions = preds_list[:, :, 5]\n",
    "    target_list = [cohesion, syntax, vocabulary, phraseology, grammar, conventions]\n",
    "\n",
    "    for t_idx, target in enumerate(target_list):\n",
    "\n",
    "        def f(x):\n",
    "            pred = np.zeros_like(target[0])\n",
    "            for i, p in enumerate(target):\n",
    "                pred += p * x[i]\n",
    "            score = metrics.mean_squared_error(\n",
    "                valid_y_cv.values[:, t_idx], pred, squared=False\n",
    "            )\n",
    "            return score\n",
    "\n",
    "        init_state = np.ones((len(target))) / len(target)\n",
    "        bounds = [(0.0, 1.0)] * len(target)\n",
    "        result = minimize(f, init_state, method=\"Nelder-Mead\", bounds=bounds)\n",
    "        print(f\"optimized_corr:{result['fun']}\")\n",
    "\n",
    "        weights = [[0] for _ in range(len(target))]\n",
    "        for i in range(len(target)):\n",
    "            weights[i] = result[\"x\"][i]\n",
    "        weights_list[t_idx].append(weights)\n",
    "        print(f\"weights:{weights}\")\n",
    "\n",
    "avg_weights_cohesion = np.mean(weights_list[0], axis=0)\n",
    "avg_weights_syntax = np.mean(weights_list[1], axis=0)\n",
    "avg_weights_vocabulary = np.mean(weights_list[2], axis=0)\n",
    "avg_weights_phraseology = np.mean(weights_list[3], axis=0)\n",
    "avg_weights_grammar = np.mean(weights_list[4], axis=0)\n",
    "avg_weights_conventions = np.mean(weights_list[5], axis=0)\n",
    "\n",
    "print()\n",
    "print(f\"cohesion averaged_weights:{avg_weights_cohesion}\")\n",
    "print(f\"syntax averaged_weights:{avg_weights_syntax}\")\n",
    "print(f\"vocabulary averaged_weights:{avg_weights_vocabulary}\")\n",
    "print(f\"phraseology averaged_weights:{avg_weights_phraseology}\")\n",
    "print(f\"grammar averaged_weights:{avg_weights_grammar}\")\n",
    "print(f\"conventions averaged_weights:{avg_weights_conventions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T18:36:33.320142Z",
     "iopub.status.busy": "2022-11-22T18:36:33.319587Z",
     "iopub.status.idle": "2022-11-22T18:36:34.661440Z",
     "shell.execute_reply": "2022-11-22T18:36:34.659792Z",
     "shell.execute_reply.started": "2022-11-22T18:36:33.320100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple_mean: mcrmse_score:0.44092151174713784, mcrmse_scores:[0.4720510272664117, 0.4493186587571681, 0.3968925323594917, 0.44337967344423296, 0.44863675854379725, 0.43525042011172543]\n",
      "cfg_0: mcrmse_score:0.44661679275644395, mcrmse_scores:[0.478136184481341, 0.4589547473544348, 0.4017579316964105, 0.44773613966828874, 0.45087779693826036, 0.44223795639992797]\n",
      "cfg_1: mcrmse_score:0.4464048391957691, mcrmse_scores:[0.4773659991581123, 0.45743327359847313, 0.4035178521296586, 0.44723533562423085, 0.4525589148944916, 0.44031765976964804]\n",
      "cfg_2: mcrmse_score:0.44448586643844323, mcrmse_scores:[0.47648330647205905, 0.4505310497008678, 0.40269257694686345, 0.4471697352664887, 0.44927198718123534, 0.4407665430631452]\n",
      "cfg_3: mcrmse_score:0.44472671646098233, mcrmse_scores:[0.47735512111121164, 0.4516886550344083, 0.40180245438441015, 0.44781363658293616, 0.4508851972175929, 0.4388152344353346]\n",
      "cfg_4: mcrmse_score:0.45587919658355097, mcrmse_scores:[0.49115707754281196, 0.46586656465627796, 0.4084097681196977, 0.450699941890301, 0.47074896757323065, 0.44839285971898696]\n",
      "cfg_5: mcrmse_score:0.4479635044015189, mcrmse_scores:[0.47839677880268405, 0.450060958718328, 0.40672601541527953, 0.45423488261511047, 0.4562313296572283, 0.4421310612004828]\n",
      "cfg_6: mcrmse_score:0.4533311047056445, mcrmse_scores:[0.4945957579568357, 0.4567572394137141, 0.4037388946679849, 0.45321687303909186, 0.4625044284302679, 0.44917343472597293]\n",
      "cfg_7: mcrmse_score:0.4566606907917121, mcrmse_scores:[0.4862305506108559, 0.4646361064133635, 0.40831554791256197, 0.45867129246871025, 0.4736084225082442, 0.4485022248365369]\n",
      "cfg_8: mcrmse_score:0.45186562985660744, mcrmse_scores:[0.47610930554639985, 0.46666382181908805, 0.40381866079369977, 0.45068033863265966, 0.4641070974371859, 0.449814554910611]\n",
      "cfg_9: mcrmse_score:0.45532022269995487, mcrmse_scores:[0.49045500083148386, 0.45871736678082126, 0.40881330030178836, 0.45635978282157724, 0.46344756490705885, 0.4541283205569997]\n",
      "cfg_10: mcrmse_score:0.45389183253006, mcrmse_scores:[0.48773070498073834, 0.46186266287524275, 0.4065325250958825, 0.45733485397276863, 0.4616254165076407, 0.4482648317480867]\n",
      "cfg_11: mcrmse_score:0.4457678844747381, mcrmse_scores:[0.4746370393868924, 0.4503152516106336, 0.3984963594385038, 0.4497555957709509, 0.4560446817566745, 0.4453583788847728]\n",
      "optimized: mcrmse_score:0.4397887897839777, mcrmse_scores:[0.46913321752709725, 0.44800039187945334, 0.3958624649719769, 0.4429642481694171, 0.4470675862931247, 0.43570482986279707]\n",
      "\n",
      "simple_mean: mcrmse_score:0.448947619204957, mcrmse_scores:[0.47933309533968105, 0.4379145996617215, 0.4104132141464085, 0.46309656337310534, 0.4627264333073295, 0.44020180940149595]\n",
      "cfg_0: mcrmse_score:0.4558411678172059, mcrmse_scores:[0.4912487704626638, 0.4424619922647926, 0.41957621543647267, 0.4707441249952413, 0.4665879630826332, 0.4444279406614318]\n",
      "cfg_1: mcrmse_score:0.45915672587084905, mcrmse_scores:[0.49545116109162285, 0.44508253642042594, 0.4224858230253303, 0.47212007513120463, 0.4705759386561434, 0.4492248209003667]\n",
      "cfg_2: mcrmse_score:0.45309133531112417, mcrmse_scores:[0.4835162011215614, 0.4440944208267599, 0.41352330573025825, 0.46564622539507067, 0.46638626938840466, 0.44538158940469]\n",
      "cfg_3: mcrmse_score:0.4541032784935443, mcrmse_scores:[0.4863957667910709, 0.44466507644324876, 0.41412312733806117, 0.46663683985746707, 0.46592440284196796, 0.4468744576894498]\n",
      "cfg_4: mcrmse_score:0.4671110973384676, mcrmse_scores:[0.49670743688594715, 0.46097723485713815, 0.41884850051636247, 0.4777244290315191, 0.48597949748972175, 0.462429485250117]\n",
      "cfg_5: mcrmse_score:0.45010048713131207, mcrmse_scores:[0.4794066845564069, 0.4365101495527329, 0.41523658967952903, 0.4613983908184014, 0.46731349989752735, 0.4407376082832748]\n",
      "cfg_6: mcrmse_score:0.4603958715931682, mcrmse_scores:[0.4899236904150033, 0.4527161313820988, 0.4190827579084562, 0.4697090902754931, 0.46922711125326566, 0.46171644832469194]\n",
      "cfg_7: mcrmse_score:0.46564766098996496, mcrmse_scores:[0.502360116440962, 0.44789438343418, 0.422475113691064, 0.48126891134093147, 0.48666321897363174, 0.45322422205902063]\n",
      "cfg_8: mcrmse_score:0.4570095654062552, mcrmse_scores:[0.48067241293120727, 0.4454368507868513, 0.41548544328141435, 0.4698451858427779, 0.4764595720167227, 0.454157927578558]\n",
      "cfg_9: mcrmse_score:0.4584501919730901, mcrmse_scores:[0.4834166517468176, 0.44969602612878656, 0.4182662635243793, 0.4697060629223037, 0.47414368437152293, 0.4554724631447303]\n",
      "cfg_10: mcrmse_score:0.46314124367020737, mcrmse_scores:[0.5016792540659375, 0.450159128001947, 0.41953841299662203, 0.4793908698167474, 0.48130786989814955, 0.44677192724184056]\n",
      "cfg_11: mcrmse_score:0.4494252013296333, mcrmse_scores:[0.4792739247898004, 0.4341051793292873, 0.4113907235880221, 0.4665578325601996, 0.46574780720046877, 0.43947574051002175]\n",
      "optimized: mcrmse_score:0.4464097232862687, mcrmse_scores:[0.47430075834469193, 0.43484393196643, 0.40915923917062713, 0.4618512997215142, 0.4604767532825707, 0.43782635723177826]\n",
      "\n",
      "simple_mean: mcrmse_score:0.45098155508927884, mcrmse_scores:[0.4870852293466662, 0.45493055443864866, 0.4095948978742574, 0.43561719629087214, 0.4676731687936636, 0.45098828379156497]\n",
      "cfg_0: mcrmse_score:0.4569099850631382, mcrmse_scores:[0.48892207328070897, 0.4584145464881401, 0.42103667271682277, 0.44043806801178753, 0.47336565155870614, 0.4592828983226634]\n",
      "cfg_1: mcrmse_score:0.45598182150842637, mcrmse_scores:[0.49275558087130034, 0.4592054942015668, 0.4190234178180204, 0.44049313946996677, 0.46747935379721794, 0.45693394289248623]\n",
      "cfg_2: mcrmse_score:0.4538764999892781, mcrmse_scores:[0.49162479441487944, 0.45482732468178283, 0.413564618913642, 0.43402238400346793, 0.4723766760141114, 0.45684320190778477]\n",
      "cfg_3: mcrmse_score:0.4534567716541396, mcrmse_scores:[0.4916421030735716, 0.45542805909024964, 0.4114268602619693, 0.4355446271665767, 0.47142285872238476, 0.4552761216100862]\n",
      "cfg_4: mcrmse_score:0.46706152472726986, mcrmse_scores:[0.5046007534423227, 0.47071076916785887, 0.4199003737025694, 0.45454968259908474, 0.48275497373303644, 0.4698525957187473]\n",
      "cfg_5: mcrmse_score:0.46079820936405985, mcrmse_scores:[0.49793972248061497, 0.4656664846684151, 0.41981783172351383, 0.44341782574478655, 0.47618755018984066, 0.4617598413771876]\n",
      "cfg_6: mcrmse_score:0.4646190518527075, mcrmse_scores:[0.5016228133534124, 0.47087996760268236, 0.4148920386533638, 0.44744927585594957, 0.48013076435860297, 0.47273945129223427]\n",
      "cfg_7: mcrmse_score:0.4704533314594208, mcrmse_scores:[0.5157305171382598, 0.47825513834067374, 0.42112501502278843, 0.4603353423765666, 0.48657340348236305, 0.46070057239587303]\n",
      "cfg_8: mcrmse_score:0.4658666401118096, mcrmse_scores:[0.5048782529201589, 0.46431788723932826, 0.4281608528687088, 0.4523774659390701, 0.48481346180227647, 0.46065191990131504]\n",
      "cfg_9: mcrmse_score:0.46032752748385763, mcrmse_scores:[0.49957397963260847, 0.4619157188672954, 0.4143222235242039, 0.4456768562416289, 0.47893318767681414, 0.46154319896059476]\n",
      "cfg_10: mcrmse_score:0.46523009676707616, mcrmse_scores:[0.49910657648338247, 0.4656551743869717, 0.4204827509622723, 0.4500796964821681, 0.4903675516616807, 0.4656888306259817]\n",
      "cfg_11: mcrmse_score:0.4526238330680678, mcrmse_scores:[0.48634174261687496, 0.45802026997757, 0.4109653549730874, 0.4371385177067725, 0.468996624876114, 0.45428048825798756]\n",
      "optimized: mcrmse_score:0.44979923973671365, mcrmse_scores:[0.48551292270231755, 0.4540516250530951, 0.40925589961803605, 0.434471961322402, 0.46535592757613015, 0.4501471021483012]\n",
      "\n",
      "simple_mean: mcrmse_score:0.44768459836914215, mcrmse_scores:[0.4725522774358075, 0.43436286946733954, 0.4153255869884508, 0.4497136299379114, 0.483352152887866, 0.43080107349747704]\n",
      "cfg_0: mcrmse_score:0.4545926242468911, mcrmse_scores:[0.4780624805591025, 0.43925971987468404, 0.424190173898549, 0.45241239212843426, 0.491224674198798, 0.44240630482177873]\n",
      "cfg_1: mcrmse_score:0.45463694668711696, mcrmse_scores:[0.4786551506405246, 0.44320551309208583, 0.4216340388964202, 0.4534669742008486, 0.4865551071272548, 0.4443048961655676]\n",
      "cfg_2: mcrmse_score:0.4532651543497335, mcrmse_scores:[0.48099546088236445, 0.44139049185005613, 0.4227976373533461, 0.4527921927907536, 0.4878578488439966, 0.43375729437788485]\n",
      "cfg_3: mcrmse_score:0.45382171430612855, mcrmse_scores:[0.4808687604719392, 0.44217584829538437, 0.4222897404667908, 0.45413885199838566, 0.4872766639069875, 0.4361804206972839]\n",
      "cfg_4: mcrmse_score:0.45863909174748163, mcrmse_scores:[0.48795127050691894, 0.4437624153570669, 0.42684943724403446, 0.4627945330649879, 0.49107875441718646, 0.43939813989469506]\n",
      "cfg_5: mcrmse_score:0.45042563021395515, mcrmse_scores:[0.4660897560568327, 0.43734630412514147, 0.4180143377525276, 0.4545812841972018, 0.4903899156470727, 0.4361321835049547]\n",
      "cfg_6: mcrmse_score:0.4566138341821832, mcrmse_scores:[0.4861300183717545, 0.4381048112028802, 0.42293497713334766, 0.4532725356103301, 0.49253668455631777, 0.44670397821846886]\n",
      "cfg_7: mcrmse_score:0.4649166367826345, mcrmse_scores:[0.489382254116635, 0.4501605195945605, 0.4244761390750139, 0.46954001344598, 0.507984823869292, 0.44795607059432535]\n",
      "cfg_8: mcrmse_score:0.45579570070898606, mcrmse_scores:[0.4743508990715161, 0.44522337602893286, 0.4212998168485484, 0.46141445014360405, 0.4931881385667577, 0.4392975235945572]\n",
      "cfg_9: mcrmse_score:0.4608807330325774, mcrmse_scores:[0.48863505674373436, 0.4466742585215095, 0.42283122172301585, 0.4635027337969231, 0.49767762139836796, 0.4459635060119138]\n",
      "cfg_10: mcrmse_score:0.45985271940009526, mcrmse_scores:[0.49084732796419894, 0.4446387188680327, 0.42551848654739466, 0.45421580326955535, 0.4987026605424888, 0.44519331920890115]\n",
      "cfg_11: mcrmse_score:0.4521721453644807, mcrmse_scores:[0.4791637149384377, 0.4385207172612227, 0.416434932672291, 0.46006092470189597, 0.48762885482594165, 0.4312237277870951]\n",
      "optimized: mcrmse_score:0.44604526720623244, mcrmse_scores:[0.4682705626207319, 0.4326477924788989, 0.4142782357143049, 0.4487724244372176, 0.4818216465289416, 0.43048094145729954]\n",
      "\n",
      "simple_mean: mcrmse_score:0.44439831122516366, mcrmse_scores:[0.47033415662890765, 0.4232548188314725, 0.4144313150900341, 0.4505597491848864, 0.4664577322585669, 0.44135209535711456]\n",
      "cfg_0: mcrmse_score:0.45045641240378886, mcrmse_scores:[0.4775823738252423, 0.4263989626165631, 0.4230824802365148, 0.45769567116746385, 0.46893230908030686, 0.44904667749664223]\n",
      "cfg_1: mcrmse_score:0.4517432062385292, mcrmse_scores:[0.4779025181975456, 0.42759785811732126, 0.423234017852278, 0.45882358993908723, 0.4704489605730071, 0.4524522927519363]\n",
      "cfg_2: mcrmse_score:0.4508693423552877, mcrmse_scores:[0.478093535837772, 0.4292724654396661, 0.4209260423215978, 0.45777894336111674, 0.4726047805723637, 0.44654028659920975]\n",
      "cfg_3: mcrmse_score:0.4515949973829423, mcrmse_scores:[0.47751213372059637, 0.42957337990874667, 0.42165234346628183, 0.4592215900076751, 0.4741227259736645, 0.4474878112206895]\n",
      "cfg_4: mcrmse_score:0.4620307837332171, mcrmse_scores:[0.48206021798191023, 0.44219449622268703, 0.42815859816260815, 0.46584606181712634, 0.49226960720022916, 0.46165572101474184]\n",
      "cfg_5: mcrmse_score:0.4474641097063791, mcrmse_scores:[0.4737801518518556, 0.4252015355312981, 0.4198741237387436, 0.45476214525200503, 0.4684081572280387, 0.44275854463633374]\n",
      "cfg_6: mcrmse_score:0.45679402564647825, mcrmse_scores:[0.48276737272563175, 0.43711546662999723, 0.42476659181253756, 0.4543507633217169, 0.4818075373997993, 0.4599564219891868]\n",
      "cfg_7: mcrmse_score:0.46539375491689355, mcrmse_scores:[0.4961967277126483, 0.44124496335125646, 0.4290322939499835, 0.4722297308302245, 0.4930749830824609, 0.4605838305747874]\n",
      "cfg_8: mcrmse_score:0.4547424330056882, mcrmse_scores:[0.47896104870392675, 0.43535642537141017, 0.41994309441747507, 0.46247890598642233, 0.47652754534931313, 0.4551875782055815]\n",
      "cfg_9: mcrmse_score:0.4528822837239501, mcrmse_scores:[0.48597703918326896, 0.436563046559863, 0.41940368739944417, 0.4558095976463459, 0.4724365400486864, 0.44710379150609264]\n",
      "cfg_10: mcrmse_score:0.45568738582827, mcrmse_scores:[0.4852500107317673, 0.43069886190595724, 0.42215596194886956, 0.4623970318420913, 0.4804283154033738, 0.453194133137561]\n",
      "cfg_11: mcrmse_score:0.45097868685474835, mcrmse_scores:[0.47303841693404824, 0.43105429138437446, 0.4200762629912384, 0.4582635938056577, 0.4743967373710312, 0.4490428186421403]\n",
      "optimized: mcrmse_score:0.44279313395179276, mcrmse_scores:[0.46723452660618225, 0.42141890979560387, 0.4135902979058707, 0.4498893216742714, 0.4641542351269271, 0.44047151260190104]\n",
      "\n",
      "optimized mean_cv score:0.4449672307929971\n",
      "optimized mean_cv score:[0.4728904  0.43819253 0.40842923 0.44758985 0.46377523 0.43892615]\n"
     ]
    }
   ],
   "source": [
    "score_cv = []\n",
    "scores_cv = []\n",
    "preds_list_valid_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "for j, preds in enumerate(preds_list_cv):\n",
    "\n",
    "    _, valid_indices = list(skf.split(train_X, train_y))[j]\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "    \n",
    "    # blending\n",
    "    preds_list_valid_cv[j] = np.zeros(preds[0].shape)\n",
    "    for i in range(preds.shape[0]):\n",
    "        preds_list_valid_cv[j][:, 0] += preds[i, :, 0] * avg_weights_cohesion[i]\n",
    "        preds_list_valid_cv[j][:, 1] += preds[i, :, 1] * avg_weights_syntax[i]\n",
    "        preds_list_valid_cv[j][:, 2] += preds[i, :, 2] * avg_weights_vocabulary[i]\n",
    "        preds_list_valid_cv[j][:, 3] += preds[i, :, 3] * avg_weights_phraseology[i]\n",
    "        preds_list_valid_cv[j][:, 4] += preds[i, :, 4] * avg_weights_grammar[i]\n",
    "        preds_list_valid_cv[j][:, 5] += preds[i, :, 5] * avg_weights_conventions[i]\n",
    "        \n",
    "    score, scores = mcrmse(valid_y_cv.values, np.mean(preds, axis=0))\n",
    "    print()\n",
    "    print(f\"simple_mean: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    for i, p in enumerate(preds):\n",
    "        score, scores = mcrmse(valid_y_cv.values, p)\n",
    "        print(f\"cfg_{i}: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "        \n",
    "    score, scores = mcrmse(valid_y_cv.values, preds_list_valid_cv[j])\n",
    "    print(f\"optimized: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    score_cv.append(score)\n",
    "    scores_cv.append(scores)\n",
    "\n",
    "print()\n",
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T18:38:15.021167Z",
     "iopub.status.busy": "2022-11-22T18:38:15.020760Z",
     "iopub.status.idle": "2022-11-22T18:38:15.028063Z",
     "shell.execute_reply": "2022-11-22T18:38:15.027008Z",
     "shell.execute_reply.started": "2022-11-22T18:38:15.021137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta-v3-base-512-reinit: mean_weight -> 0.08815145125656429\n",
      "deberta-v3-base-4096-reinit: mean_weight -> 0.09672884018322093\n",
      "deberta-v3-large-512-reinit: mean_weight -> 0.06307039726581137\n",
      "deberta-v3-large-4096-reinit: mean_weight -> 0.08082699843144515\n",
      "bigbird-roberta-large-4096-reinit: mean_weight -> 0.06029814640283086\n",
      "deberta-large-512-reinit: mean_weight -> 0.15154171542860648\n",
      "electra-large-512-reinit: mean_weight -> 0.06399589048253156\n",
      "longformer-base-4096-reinit: mean_weight -> 0.015908246062988483\n",
      "muppet-large-512-reinit: mean_weight -> 0.13418874247733906\n",
      "roberta-large-512-reinit: mean_weight -> 0.04655535988213684\n",
      "xlm-roberta-large-512-reinit: mean_weight -> 0.020489615270127694\n",
      "deberta-xlarge-512-reinit: mean_weight -> 0.17961988879406493\n"
     ]
    }
   ],
   "source": [
    "for cfg, w in zip(cfg_list, np.mean(weights_list, axis=(0,1))):\n",
    "    print(f\"{cfg['save_weight_folder'][9:]}: mean_weight -> {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blending test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T13:58:39.178618Z",
     "iopub.status.busy": "2022-11-22T13:58:39.178229Z",
     "iopub.status.idle": "2022-11-22T14:00:27.677214Z",
     "shell.execute_reply": "2022-11-22T14:00:27.676041Z",
     "shell.execute_reply.started": "2022-11-22T13:58:39.178586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f332f82a264f7d86058b463255ffef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b9e67867bf441dbbaea41b1603273e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd51c63adecb4fe5b766c52b43a7bab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432c932cce6c49418f121a5e26496d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555e2ef79f794c33a55fee333e8ebd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfc2a3160854186bfd7a10c341b217f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a9672c57aa414ebced0fef83a370bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4929edc6c84aa09beda81b80d9f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e6ab25d5b84db6b628471be1840036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad159ed4ea14ddd99c60cf6feb46091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_list_test_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "score_cv = []\n",
    "scores_cv = []\n",
    "for j, fold_n in enumerate(fold_list):\n",
    "    preds_list = []\n",
    "\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        test_preds = one_fold_test(cfg, test_X, fold_n)\n",
    "        preds_list.append(test_preds)\n",
    "        del test_preds\n",
    "        gc.collect()\n",
    "\n",
    "    preds_list = np.array(preds_list)\n",
    "    \n",
    "    # blending\n",
    "    preds_list_test_cv[j] = np.zeros(preds_list[0].shape)\n",
    "    for i in range(preds_list.shape[0]):\n",
    "        preds_list_test_cv[j][:, 0] += preds_list[i, :, 0] * avg_weights_cohesion[i]\n",
    "        preds_list_test_cv[j][:, 1] += preds_list[i, :, 1] * avg_weights_syntax[i]\n",
    "        preds_list_test_cv[j][:, 2] += preds_list[i, :, 2] * avg_weights_vocabulary[i]\n",
    "        preds_list_test_cv[j][:, 3] += preds_list[i, :, 3] * avg_weights_phraseology[i]\n",
    "        preds_list_test_cv[j][:, 4] += preds_list[i, :, 4] * avg_weights_grammar[i]\n",
    "        preds_list_test_cv[j][:, 5] += preds_list[i, :, 5] * avg_weights_conventions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T14:01:42.819382Z",
     "iopub.status.busy": "2022-11-22T14:01:42.819012Z",
     "iopub.status.idle": "2022-11-22T14:01:42.824942Z",
     "shell.execute_reply": "2022-11-22T14:01:42.823725Z",
     "shell.execute_reply.started": "2022-11-22T14:01:42.819350Z"
    }
   },
   "outputs": [],
   "source": [
    "final_test_preds = np.mean(preds_list_test_cv, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T14:01:44.999355Z",
     "iopub.status.busy": "2022-11-22T14:01:44.998969Z",
     "iopub.status.idle": "2022-11-22T14:01:45.004309Z",
     "shell.execute_reply": "2022-11-22T14:01:45.003091Z",
     "shell.execute_reply.started": "2022-11-22T14:01:44.999320Z"
    }
   },
   "outputs": [],
   "source": [
    "final_test_preds = np.clip(final_test_preds, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T14:01:45.779129Z",
     "iopub.status.busy": "2022-11-22T14:01:45.778756Z",
     "iopub.status.idle": "2022-11-22T14:01:45.788708Z",
     "shell.execute_reply": "2022-11-22T14:01:45.787743Z",
     "shell.execute_reply.started": "2022-11-22T14:01:45.779097Z"
    },
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1662355541554,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "uAdePK_fDobS"
   },
   "outputs": [],
   "source": [
    "sub[\"cohesion\"] = final_test_preds[:, 0]\n",
    "sub[\"syntax\"] = final_test_preds[:, 1]\n",
    "sub[\"vocabulary\"] = final_test_preds[:, 2]\n",
    "sub[\"phraseology\"] = final_test_preds[:, 3]\n",
    "sub[\"grammar\"] = final_test_preds[:, 4]\n",
    "sub[\"conventions\"] = final_test_preds[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T14:01:46.164298Z",
     "iopub.status.busy": "2022-11-22T14:01:46.163962Z",
     "iopub.status.idle": "2022-11-22T14:01:46.193114Z",
     "shell.execute_reply": "2022-11-22T14:01:46.192022Z",
     "shell.execute_reply.started": "2022-11-22T14:01:46.164266Z"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1662355545119,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "mRQNLOkKDobV",
    "outputId": "286d11ea-aa38-4b1f-ee51-003118c75584"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.883897</td>\n",
       "      <td>2.775009</td>\n",
       "      <td>3.097567</td>\n",
       "      <td>2.973784</td>\n",
       "      <td>2.719742</td>\n",
       "      <td>2.674564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.629768</td>\n",
       "      <td>2.409478</td>\n",
       "      <td>2.743813</td>\n",
       "      <td>2.381966</td>\n",
       "      <td>2.135197</td>\n",
       "      <td>2.639184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.564441</td>\n",
       "      <td>3.381812</td>\n",
       "      <td>3.616520</td>\n",
       "      <td>3.518507</td>\n",
       "      <td>3.433326</td>\n",
       "      <td>3.293942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.883897  2.775009    3.097567     2.973784  2.719742   \n",
       "1  000BAD50D026  2.629768  2.409478    2.743813     2.381966  2.135197   \n",
       "2  00367BB2546B  3.564441  3.381812    3.616520     3.518507  3.433326   \n",
       "\n",
       "   conventions  \n",
       "0     2.674564  \n",
       "1     2.639184  \n",
       "2     3.293942  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T21:43:44.819286Z",
     "iopub.status.busy": "2022-11-19T21:43:44.818792Z",
     "iopub.status.idle": "2022-11-19T21:43:44.832806Z",
     "shell.execute_reply": "2022-11-19T21:43:44.831258Z",
     "shell.execute_reply.started": "2022-11-19T21:43:44.819241Z"
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1662355556141,
     "user": {
      "displayName": "Kento Morita",
      "userId": "02337995763048559377"
     },
     "user_tz": -540
    },
    "id": "spXa_S_QDobY"
   },
   "outputs": [],
   "source": [
    "sub.to_csv(f\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate pseudo label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:40:54.613057Z",
     "iopub.status.busy": "2022-11-23T14:40:54.612411Z",
     "iopub.status.idle": "2022-11-23T14:40:55.058896Z",
     "shell.execute_reply": "2022-11-23T14:40:55.058353Z",
     "shell.execute_reply.started": "2022-11-23T14:40:54.613030Z"
    }
   },
   "outputs": [],
   "source": [
    "# read external data\n",
    "ex = pd.read_csv(\"../data/input/past_fb_data.csv\")\n",
    "\n",
    "ex_X = ex[\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:40:56.121813Z",
     "iopub.status.busy": "2022-11-23T14:40:56.121101Z",
     "iopub.status.idle": "2022-11-23T14:40:56.126077Z",
     "shell.execute_reply": "2022-11-23T14:40:56.125492Z",
     "shell.execute_reply.started": "2022-11-23T14:40:56.121782Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_fold_pseudo(cfg, ex_X, fold_n):\n",
    "    print(f\"[fold_{fold_n}]\")\n",
    "    seed_everything(cfg[\"general\"][\"seed\"], workers=True)\n",
    "\n",
    "    model = TransformersRegressorInference(cfg, f\"{cfg['save_weight_folder']}/last_epoch_fold{fold_n}.ckpt\")\n",
    "    pseudo_preds = model.predict(ex_X)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return pseudo_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:40:57.579290Z",
     "iopub.status.busy": "2022-11-23T14:40:57.578463Z",
     "iopub.status.idle": "2022-11-23T14:40:57.583353Z",
     "shell.execute_reply": "2022-11-23T14:40:57.582616Z",
     "shell.execute_reply.started": "2022-11-23T14:40:57.579266Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_weights_cohesion = [0.05193772, 0.11036315, 0.01717836, 0.06184517, 0.24583778, 0.2668852, 0.2475308]\n",
    "avg_weights_syntax = [0.15986115, 0.05737773, 0.08191739, 0.06150111, 0.26768993, 0.06645094, 0.30885836]\n",
    "avg_weights_vocabulary = [0.0599905, 0.06431446, 0.11436567, 0.08179424, 0.09350644, 0.19307011, 0.39327719]\n",
    "avg_weights_phraseology = [0.04839435, 0.15866904, 0.22683944, 0.08257008, 0.2055661, 0.15263263, 0.12525981]\n",
    "avg_weights_grammar = [0.13787544, 0.21311838, 0.09743774, 0.08402591, 0.12684375, 0.11145722, 0.23145577]\n",
    "avg_weights_conventions = [0.05605593, 0.10720015, 0.11871781, 0.14182469, 0.21086025, 0.14346338, 0.22574695]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T16:05:08.569675Z",
     "iopub.status.busy": "2022-11-23T16:05:08.568686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_base_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_base_512_reinit/last_epoch_fold3.ckpt\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c53db91fff48979216082789d50412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.658 3.576 3.734 3.904 4.016 3.482]\n",
      " [3.352 3.373 3.66  3.516 3.635 3.385]\n",
      " [3.082 2.975 3.273 3.287 3.379 3.043]\n",
      " [3.732 3.758 3.865 3.852 3.906 3.89 ]\n",
      " [3.74  3.791 4.03  4.08  4.168 3.74 ]\n",
      " [2.854 2.787 3.34  3.293 3.236 2.705]\n",
      " [3.406 3.348 3.559 3.557 3.734 3.387]\n",
      " [4.2   4.164 4.32  4.406 4.555 4.34 ]\n",
      " [4.297 4.395 4.42  4.55  4.69  4.383]\n",
      " [4.01  4.08  4.344 4.344 4.387 4.055]]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_base_4096_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_base_4096_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8763bc3ca448508758fb51786e7d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.643 3.549 3.71  3.86  3.936 3.422]\n",
      " [3.293 3.34  3.604 3.45  3.62  3.357]\n",
      " [3.053 2.967 3.271 3.283 3.389 3.06 ]\n",
      " [3.63  3.69  3.822 3.771 3.895 3.795]\n",
      " [3.709 3.771 3.965 4.016 4.11  3.72 ]\n",
      " [2.871 2.787 3.316 3.248 3.174 2.729]\n",
      " [3.379 3.299 3.523 3.523 3.717 3.387]\n",
      " [4.082 4.05  4.195 4.3   4.406 4.2  ]\n",
      " [4.203 4.277 4.26  4.406 4.58  4.246]\n",
      " [4.195 4.24  4.684 4.434 4.438 4.137]]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_large_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_large_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cebee72de64c61b9bf466d02fad37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.482 3.533 3.477 3.553 3.777 3.322]\n",
      " [3.314 3.361 3.51  3.484 3.455 3.299]\n",
      " [3.17  3.121 3.188 3.258 3.238 3.02 ]\n",
      " [3.715 3.791 3.785 3.787 3.912 3.887]\n",
      " [3.74  3.709 3.941 4.004 3.994 3.652]\n",
      " [2.822 2.766 3.15  3.121 3.084 2.738]\n",
      " [3.137 3.166 3.32  3.475 3.596 3.166]\n",
      " [4.125 4.113 4.25  4.25  4.395 4.07 ]\n",
      " [4.188 4.13  4.203 4.297 4.355 4.13 ]\n",
      " [3.87  3.855 3.965 3.982 4.125 3.82 ]]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_large_4096_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_large_4096_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee6683a2e064261afa04ff6a3b566f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.447 3.506 3.46  3.518 3.78  3.32 ]\n",
      " [3.354 3.404 3.543 3.506 3.498 3.324]\n",
      " [3.145 3.107 3.164 3.232 3.238 3.004]\n",
      " [3.729 3.824 3.834 3.8   3.982 3.904]\n",
      " [3.701 3.695 3.896 3.982 3.979 3.648]\n",
      " [2.8   2.754 3.127 3.102 3.08  2.734]\n",
      " [3.074 3.127 3.275 3.428 3.586 3.121]\n",
      " [4.08  4.066 4.195 4.223 4.363 4.043]\n",
      " [4.133 4.07  4.14  4.28  4.348 4.117]\n",
      " [4.023 3.998 4.17  4.19  4.293 3.914]]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_large_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_large_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61799df4522144828c5dcebb9fb8e7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.36  3.512 3.68  3.578 3.695 3.229]\n",
      " [3.441 3.516 3.77  3.625 3.67  3.436]\n",
      " [3.172 3.105 3.322 3.346 3.24  2.957]\n",
      " [3.748 3.771 3.777 3.768 3.762 3.87 ]\n",
      " [3.68  3.67  3.965 3.871 3.963 3.754]\n",
      " [2.807 2.762 3.328 3.129 2.918 2.717]\n",
      " [3.094 3.06  3.145 3.238 3.469 3.158]\n",
      " [4.332 4.332 4.543 4.293 4.387 4.277]\n",
      " [4.22  4.3   4.42  4.27  4.344 4.133]\n",
      " [4.16  4.184 4.46  4.273 4.21  4.03 ]]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/muppet-roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at facebook/muppet-roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/muppet_large_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/muppet_large_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a029573ca0456e8d9b97b3e5daaca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.691 3.445 3.613 3.664 3.643 3.355]\n",
      " [3.47  3.371 3.457 3.477 3.607 3.422]\n",
      " [3.172 3.031 3.26  3.307 3.41  2.984]\n",
      " [3.992 4.008 4.06  4.09  4.164 4.25 ]\n",
      " [3.95  3.96  4.15  4.074 4.32  4.06 ]\n",
      " [2.818 2.693 3.158 3.125 3.098 2.73 ]\n",
      " [3.176 3.11  3.361 3.248 3.36  3.059]\n",
      " [4.293 4.105 4.367 4.33  4.414 4.12 ]\n",
      " [4.465 4.188 4.41  4.363 4.508 4.336]\n",
      " [4.52  4.4   4.66  4.348 4.406 4.258]]\n",
      "[fold_3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_xlarge_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_xlarge_512_reinit/last_epoch_fold3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9824a88ac747e297675de56560a071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.459 3.467 3.635 3.71  3.693 3.297]\n",
      " [3.346 3.541 3.582 3.572 3.73  3.482]\n",
      " [3.143 3.244 3.314 3.4   3.43  3.062]\n",
      " [3.652 3.662 3.646 3.686 3.707 3.807]\n",
      " [3.838 3.848 4.055 4.13  4.203 3.867]\n",
      " [2.908 2.914 3.25  3.273 3.184 2.803]\n",
      " [3.09  3.06  3.19  3.234 3.355 3.072]\n",
      " [4.137 4.227 4.26  4.29  4.453 4.35 ]\n",
      " [4.32  4.21  4.332 4.23  4.332 4.203]\n",
      " [4.242 4.25  4.46  4.438 4.406 4.168]]\n",
      "[[3.53201294 3.51904297 3.61486816 3.65673828 3.80737305 3.33312988]\n",
      " [3.40228271 3.47473145 3.57177734 3.52001953 3.6340332  3.41357422]\n",
      " [3.14968872 3.12695312 3.27380371 3.30383301 3.36035156 3.02600098]\n",
      " [3.7800293  3.7644043  3.7956543  3.81799316 3.88354492 3.92468262]\n",
      " [3.80535889 3.78747559 4.0333252  4.00622559 4.13037109 3.80615234]\n",
      " [2.84841919 2.81933594 3.22949219 3.16894531 3.13378906 2.75415039]\n",
      " [3.16729736 3.14672852 3.28564453 3.3684082  3.54907227 3.16931152]\n",
      " [4.22698975 4.22314453 4.30200195 4.28845215 4.43994141 4.22521973]\n",
      " [4.31243896 4.26586914 4.328125   4.32080078 4.46801758 4.21691895]\n",
      " [4.26495361 4.18115234 4.42871094 4.26098633 4.35766602 4.08081055]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_base_512_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_base_512_reinit/last_epoch_fold4.ckpt\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e198250d8a5a441ba0b2b4817c150bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.553 3.482 3.607 3.768 3.887 3.34 ]\n",
      " [3.287 3.326 3.525 3.361 3.61  3.312]\n",
      " [3.102 2.988 3.236 3.273 3.37  3.012]\n",
      " [3.729 3.736 3.875 3.836 3.838 3.883]\n",
      " [3.732 3.738 3.898 3.947 4.094 3.643]\n",
      " [2.805 2.785 3.21  3.178 3.201 2.645]\n",
      " [3.271 3.217 3.408 3.432 3.607 3.236]\n",
      " [4.098 4.04  4.08  4.215 4.383 4.152]\n",
      " [4.258 4.297 4.254 4.42  4.457 4.22 ]\n",
      " [3.842 3.906 4.066 4.117 4.215 3.818]]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_base_4096_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_base_4096_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4a65e21442442dac1bc41d855a799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.59  3.498 3.596 3.78  3.887 3.371]\n",
      " [3.318 3.363 3.53  3.379 3.648 3.346]\n",
      " [3.088 2.99  3.223 3.25  3.361 3.02 ]\n",
      " [3.572 3.61  3.744 3.695 3.713 3.73 ]\n",
      " [3.752 3.758 3.865 3.943 4.086 3.66 ]\n",
      " [2.846 2.814 3.219 3.184 3.21  2.664]\n",
      " [3.27  3.203 3.412 3.443 3.637 3.277]\n",
      " [4.082 4.027 4.04  4.195 4.348 4.098]\n",
      " [4.2   4.23  4.164 4.38  4.434 4.15 ]\n",
      " [4.082 3.95  4.477 4.24  4.266 3.984]]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_large_512_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_large_512_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb03243b2eb74c0e9e253e2ff5a3dc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.35  3.467 3.428 3.375 3.73  3.268]\n",
      " [3.215 3.31  3.44  3.346 3.406 3.16 ]\n",
      " [3.174 3.13  3.229 3.24  3.338 2.947]\n",
      " [3.56  3.635 3.68  3.564 3.693 3.691]\n",
      " [3.848 3.832 4.004 4.02  4.1   3.762]\n",
      " [2.775 2.69  3.107 3.03  3.09  2.658]\n",
      " [3.06  3.053 3.291 3.348 3.564 3.111]\n",
      " [4.156 4.22  4.28  4.26  4.49  4.17 ]\n",
      " [4.203 4.184 4.184 4.332 4.39  4.17 ]\n",
      " [3.89  3.941 3.951 3.984 4.17  3.887]]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_v3_large_4096_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_v3_large_4096_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023c23f48c1748f0b90e57eb8868d91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.396 3.508 3.451 3.39  3.78  3.299]\n",
      " [3.23  3.35  3.447 3.346 3.426 3.176]\n",
      " [3.184 3.13  3.227 3.238 3.305 2.955]\n",
      " [3.586 3.668 3.688 3.549 3.703 3.703]\n",
      " [3.814 3.771 3.943 3.967 4.06  3.727]\n",
      " [2.729 2.668 3.09  2.994 3.074 2.662]\n",
      " [3.037 3.047 3.285 3.334 3.53  3.105]\n",
      " [4.12  4.17  4.215 4.203 4.473 4.113]\n",
      " [4.164 4.14  4.13  4.293 4.395 4.14 ]\n",
      " [4.094 4.08  4.227 4.21  4.367 4.016]]\n",
      "[fold_4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /notebooks/src/lightning_logs\n",
      "Restoring states from the checkpoint path at ../../weights/deberta_large_512_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../weights/deberta_large_512_reinit/last_epoch_fold4.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf797165f16649b09fc631241909c365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_list = [3, 4]\n",
    "pseudo_list_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "for fold_n in fold_list:\n",
    "    preds_list = []\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        pseudo_preds = one_fold_pseudo(cfg, ex_X, fold_n)\n",
    "        preds_list.append(pseudo_preds)\n",
    "        print(pseudo_preds[:10])\n",
    "        del pseudo_preds\n",
    "        gc.collect()\n",
    "        \n",
    "    preds_list = np.array(preds_list)\n",
    "    \n",
    "    # blending\n",
    "    pseudo_list_cv[fold_n] = np.zeros(preds_list[0].shape)\n",
    "    for i in range(preds_list.shape[0]):\n",
    "        pseudo_list_cv[fold_n][:, 0] += preds_list[i, :, 0] * avg_weights_cohesion[i]\n",
    "        pseudo_list_cv[fold_n][:, 1] += preds_list[i, :, 1] * avg_weights_syntax[i]\n",
    "        pseudo_list_cv[fold_n][:, 2] += preds_list[i, :, 2] * avg_weights_vocabulary[i]\n",
    "        pseudo_list_cv[fold_n][:, 3] += preds_list[i, :, 3] * avg_weights_phraseology[i]\n",
    "        pseudo_list_cv[fold_n][:, 4] += preds_list[i, :, 4] * avg_weights_grammar[i]\n",
    "        pseudo_list_cv[fold_n][:, 5] += preds_list[i, :, 5] * avg_weights_conventions[i]\n",
    "    print(pseudo_list_cv[fold_n][:10])\n",
    "    \n",
    "    ex = pd.read_csv(\"../data/input/past_fb_data.csv\")\n",
    "    cliped = np.clip(pseudo_list_cv[fold_n], 1, 5)\n",
    "    ex[\"cohesion\"] = cliped[:, 0]\n",
    "    ex[\"syntax\"] = cliped[:, 1]\n",
    "    ex[\"vocabulary\"] = cliped[:, 2]\n",
    "    ex[\"phraseology\"] = cliped[:, 3]\n",
    "    ex[\"grammar\"] = cliped[:, 4]\n",
    "    ex[\"conventions\"] = cliped[:, 5]\n",
    "    ex.to_csv(f\"../data/pseudo/pseudo_fold_{fold_n}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:20:37.313011Z",
     "iopub.status.busy": "2022-11-23T14:20:37.312705Z",
     "iopub.status.idle": "2022-11-23T14:20:39.277684Z",
     "shell.execute_reply": "2022-11-23T14:20:39.276948Z",
     "shell.execute_reply.started": "2022-11-23T14:20:37.312984Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in fold_list:\n",
    "    ex = pd.read_csv(\"../data/input/past_fb_data.csv\")\n",
    "    cliped = np.clip(pseudo_list_cv[i], 1, 5)\n",
    "    ex[\"cohesion\"] = cliped[:, 0]\n",
    "    ex[\"syntax\"] = cliped[:, 1]\n",
    "    ex[\"vocabulary\"] = cliped[:, 2]\n",
    "    ex[\"phraseology\"] = cliped[:, 3]\n",
    "    ex[\"grammar\"] = cliped[:, 4]\n",
    "    ex[\"conventions\"] = cliped[:, 5]\n",
    "    ex.to_csv(f\"../data/pseudo/pseudo_fold_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate pseudo label (with optimize and blending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T16:24:45.703457Z",
     "iopub.status.busy": "2022-11-22T16:24:45.703068Z",
     "iopub.status.idle": "2022-11-22T16:24:46.538784Z",
     "shell.execute_reply": "2022-11-22T16:24:46.537814Z",
     "shell.execute_reply.started": "2022-11-22T16:24:45.703424Z"
    }
   },
   "outputs": [],
   "source": [
    "# read external data\n",
    "ex = pd.read_csv(\"../input/past-fb-data/past_fb_data.csv\")\n",
    "\n",
    "ex_train_X = ex[\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T16:24:48.194516Z",
     "iopub.status.busy": "2022-11-22T16:24:48.194148Z",
     "iopub.status.idle": "2022-11-22T16:24:48.203262Z",
     "shell.execute_reply": "2022-11-22T16:24:48.201947Z",
     "shell.execute_reply.started": "2022-11-22T16:24:48.194485Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_fold_valid_pseudo(skf, cfg, valid_X, valid_y, ex_train_X, fold_n):\n",
    "    print(f\"[fold_{fold_n}]\")\n",
    "    seed_everything(cfg[\"general\"][\"seed\"], workers=True)\n",
    "\n",
    "    model = TransformersRegressorInference(cfg, f\"{cfg['save_weight_folder']}/last_epoch_fold{fold_n}.ckpt\")\n",
    "    valid_preds = model.predict(valid_X)\n",
    "    pseudo_preds = model.predict(ex_train_X)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    score, scores = mcrmse(valid_y.values, valid_preds)\n",
    "    print(f\"mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    return valid_preds, pseudo_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T16:25:05.215845Z",
     "iopub.status.busy": "2022-11-22T16:25:05.215443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinit 1 layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b097b827dea40eebedcf5eca498dfc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dc7ee7dd0a4907905904e7fda2b2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_list = range(cfg1[\"general\"][\"n_splits\"])\n",
    "preds_list_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "pseudo_list_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "weights_list = [[] for _ in range(6)]\n",
    "skf = MultilabelStratifiedKFold(\n",
    "    n_splits=cfg1[\"general\"][\"n_splits\"], shuffle=True, random_state=cfg1[\"general\"][\"seed\"]\n",
    ")\n",
    "for j, fold_n in enumerate(fold_list):\n",
    "    preds_list = []\n",
    "    pseudo_list = []\n",
    "    _, valid_indices = list(skf.split(train_X, train_y))[fold_n]\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        valid_preds, pseudo_preds = one_fold_valid_pseudo(skf, cfg, valid_X_cv, valid_y_cv, ex_train_X, fold_n)\n",
    "        preds_list.append(valid_preds)\n",
    "        pseudo_list.append(pseudo_preds)\n",
    "        del valid_preds\n",
    "        gc.collect()\n",
    "\n",
    "    score, scores = mcrmse(valid_y_cv.values, np.mean(preds_list, axis=0))\n",
    "    print()\n",
    "    print(f\"simple_mean: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    for i, p in enumerate(preds_list):\n",
    "        score, scores = mcrmse(valid_y_cv.values, p)\n",
    "        print(f\"cfg_{i}: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "\n",
    "    preds_list = np.array(preds_list)\n",
    "    pseudo_list = np.array(pseudo_list)\n",
    "    preds_list_cv[j] = preds_list\n",
    "    pseudo_list_cv[j] = pseudo_list\n",
    "    cohesion = preds_list[:, :, 0]\n",
    "    syntax = preds_list[:, :, 1]\n",
    "    vocabulary = preds_list[:, :, 2]\n",
    "    phraseology = preds_list[:, :, 3]\n",
    "    grammar = preds_list[:, :, 4]\n",
    "    conventions = preds_list[:, :, 5]\n",
    "    target_list = [cohesion, syntax, vocabulary, phraseology, grammar, conventions]\n",
    "\n",
    "    for t_idx, target in enumerate(target_list):\n",
    "\n",
    "        def f(x):\n",
    "            pred = np.zeros_like(target[0])\n",
    "            for i, p in enumerate(target):\n",
    "                pred += p * x[i]\n",
    "            score = metrics.mean_squared_error(\n",
    "                valid_y_cv.values[:, t_idx], pred, squared=False\n",
    "            )\n",
    "            return score\n",
    "\n",
    "        init_state = np.ones((len(target))) / len(target)\n",
    "        bounds = [(0.0, 1.0)] * len(target)\n",
    "        result = minimize(f, init_state, method=\"Nelder-Mead\", bounds=bounds)\n",
    "        print(f\"optimized_corr:{result['fun']}\")\n",
    "\n",
    "        weights = [[0] for _ in range(len(target))]\n",
    "        for i in range(len(target)):\n",
    "            weights[i] = result[\"x\"][i]\n",
    "        weights_list[t_idx].append(weights)\n",
    "        print(f\"weights:{weights}\")\n",
    "\n",
    "avg_weights_cohesion = np.mean(weights_list[0], axis=0)\n",
    "avg_weights_syntax = np.mean(weights_list[1], axis=0)\n",
    "avg_weights_vocabulary = np.mean(weights_list[2], axis=0)\n",
    "avg_weights_phraseology = np.mean(weights_list[3], axis=0)\n",
    "avg_weights_grammar = np.mean(weights_list[4], axis=0)\n",
    "avg_weights_conventions = np.mean(weights_list[5], axis=0)\n",
    "\n",
    "print()\n",
    "print(f\"cohesion averaged_weights:{avg_weights_cohesion}\")\n",
    "print(f\"syntax averaged_weights:{avg_weights_syntax}\")\n",
    "print(f\"vocabulary averaged_weights:{avg_weights_vocabulary}\")\n",
    "print(f\"phraseology averaged_weights:{avg_weights_phraseology}\")\n",
    "print(f\"grammar averaged_weights:{avg_weights_grammar}\")\n",
    "print(f\"conventions averaged_weights:{avg_weights_conventions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cv = []\n",
    "scores_cv = []\n",
    "preds_list_valid_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "pseudo_list_valid_cv = [[] for i in range(cfg1[\"general\"][\"n_splits\"])]\n",
    "for j, (preds, pseudo) in enumerate(zip(preds_list_cv, pseudo_list_cv)):\n",
    "\n",
    "    _, valid_indices = list(skf.split(train_X, train_y))[j]\n",
    "    valid_X_cv, valid_y_cv = (\n",
    "        train_X.iloc[valid_indices].reset_index(drop=True),\n",
    "        train_y.iloc[valid_indices].reset_index(drop=True),\n",
    "    )\n",
    "    \n",
    "    # blending\n",
    "    preds_list_valid_cv[j] = np.zeros(preds[0].shape)\n",
    "    pseudo_list_valid_cv[j] = np.zeros(pseudo[0].shape)\n",
    "    for i in range(preds_list.shape[0]):\n",
    "        preds_list_valid_cv[j][:, 0] += preds[i, :, 0] * avg_weights_cohesion[i]\n",
    "        preds_list_valid_cv[j][:, 1] += preds[i, :, 1] * avg_weights_syntax[i]\n",
    "        preds_list_valid_cv[j][:, 2] += preds[i, :, 2] * avg_weights_vocabulary[i]\n",
    "        preds_list_valid_cv[j][:, 3] += preds[i, :, 3] * avg_weights_phraseology[i]\n",
    "        preds_list_valid_cv[j][:, 4] += preds[i, :, 4] * avg_weights_grammar[i]\n",
    "        preds_list_valid_cv[j][:, 5] += preds[i, :, 5] * avg_weights_conventions[i]\n",
    "        \n",
    "        pseudo_list_valid_cv[j][:, 0] += pseudo[i, :, 0] * avg_weights_cohesion[i]\n",
    "        pseudo_list_valid_cv[j][:, 1] += pseudo[i, :, 1] * avg_weights_syntax[i]\n",
    "        pseudo_list_valid_cv[j][:, 2] += pseudo[i, :, 2] * avg_weights_vocabulary[i]\n",
    "        pseudo_list_valid_cv[j][:, 3] += pseudo[i, :, 3] * avg_weights_phraseology[i]\n",
    "        pseudo_list_valid_cv[j][:, 4] += pseudo[i, :, 4] * avg_weights_grammar[i]\n",
    "        pseudo_list_valid_cv[j][:, 5] += pseudo[i, :, 5] * avg_weights_conventions[i]\n",
    "        \n",
    "    score, scores = mcrmse(valid_y_cv.values, preds_list_valid_cv[j])\n",
    "    print(f\"optimized: mcrmse_score:{score}, mcrmse_scores:{scores}\")\n",
    "    score_cv.append(score)\n",
    "    scores_cv.append(scores)\n",
    "\n",
    "print(f\"optimized mean_cv score:{np.mean(score_cv)}\")\n",
    "print(f\"optimized mean_cv score:{np.mean(scores_cv, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cfg1[\"general\"][\"n_splits\"]):\n",
    "    ex = pd.read_csv(\"../data/input/past_fb_data.csv\")\n",
    "    ex[\"cohesion\"] = pseudo_list_valid_cv[i][:, 0]\n",
    "    ex[\"syntax\"] = pseudo_list_valid_cv[i][:, 1]\n",
    "    ex[\"vocabulary\"] = pseudo_list_valid_cv[i][:, 2]\n",
    "    ex[\"phraseology\"] = pseudo_list_valid_cv[i][:, 3]\n",
    "    ex[\"grammar\"] = pseudo_list_valid_cv[i][:, 4]\n",
    "    ex[\"conventions\"] = pseudo_list_valid_cv[i][:, 5]\n",
    "    ex.to_csv(f\"pseudo_fold_{i}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
